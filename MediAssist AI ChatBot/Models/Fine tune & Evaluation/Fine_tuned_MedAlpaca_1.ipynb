{"cells":[{"cell_type":"code","execution_count":null,"id":"bf65d2a9-c9d8-4a3c-a5a5-5e1634a13eff","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bf65d2a9-c9d8-4a3c-a5a5-5e1634a13eff","outputId":"2161125c-3354-4ec1-a8f0-dbb0eaaaacc5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (4.3.0)\n","Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.17.1)\n","Requirement already satisfied: trl in /opt/conda/lib/python3.10/site-packages (0.24.0)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.57.1)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.3.3)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.9.0)\n","Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.8.7)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.9.2)\n","Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n","Requirement already satisfied: bert_score in /opt/conda/lib/python3.10/site-packages (0.3.13)\n","Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.10/site-packages (5.1.2)\n","Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.48.1)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.11.0)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.6)\n","Requirement already satisfied: pyarrow>=21.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (22.0.0)\n","Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.4.0)\n","Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.5)\n","Requirement already satisfied: httpx<1.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.28.1)\n","Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2023.12.2)\n","Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.36.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.0)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.6.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2025.10.23)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2025.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.15.0)\n","Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.10/site-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.10/site-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.10/site-packages (from torch) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.10/site-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.10/site-packages (from torch) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.1.3)\n","Requirement already satisfied: triton==3.5.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.5.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.13)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.10)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.3.6)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.20.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.12.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (68.2.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.5.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.5.2)\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (2.3.1)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.10.7)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.7.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.15.3)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (10.0.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (4.1.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (2023.11.17)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n","Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (3.4)\n","Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n","Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: blis<1.4.0,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.2.0)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.4.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.9)\n","Requirement already satisfied: pyparsing>=3 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (3.2.5)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (23.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n","Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (2.0.0)\n","Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.0.4)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install datasets peft trl transformers pandas torch spacy nltk rouge_score bert_score sentence_transformers bitsandbytes accelerate sentencepiece"]},{"cell_type":"code","execution_count":null,"id":"943fb053-9de5-472f-a6fd-aae16b7f6fce","metadata":{"id":"943fb053-9de5-472f-a6fd-aae16b7f6fce","outputId":"b8613913-0692-4240-e573-dd2949dfe0d6"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /opt/conda/lib/python3.10/site-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n","  warn(\n"]}],"source":["import os\n","import json\n","import pandas as pd\n","import torch\n","from datasets import load_dataset, Dataset\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel, PeftModelForCausalLM\n","from trl import SFTTrainer\n","\n","from peft import LoraConfig, get_peft_model, PeftModel\n","from trl import SFTTrainer\n","from transformers import TrainingArguments, TrainerCallback\n","import json\n","import os\n","\n","# Note: MedAlpaca-7B is publicly available on Hugging Face\n","# No special authentication required\n","\n","# Custom callback to monitor loss and stop training when loss < 0.1\n","class EarlyStoppingOnLossCallback(TrainerCallback):\n","    \"\"\"\n","    Custom callback to save checkpoint and stop training when loss drops below threshold\n","    \"\"\"\n","    def __init__(self, target_loss_threshold=0.1, patience=50, auto_stop=True):\n","        self.target_loss_threshold = target_loss_threshold\n","        self.patience = patience\n","        self.auto_stop = auto_stop\n","        self.steps_below_threshold = 0\n","        self.best_checkpoint_saved = False\n","\n","    def on_log(self, args, state, control, logs=None, **kwargs):\n","        if logs is not None and \"loss\" in logs:\n","            current_loss = logs[\"loss\"]\n","            current_step = state.global_step\n","\n","            print(f\"\\n[Step {current_step}] Current Loss: {current_loss:.4f}\")\n","\n","            # Check if loss is below threshold\n","            if current_loss < self.target_loss_threshold:\n","                self.steps_below_threshold += 1\n","                print(f\"âœ… Loss below {self.target_loss_threshold}! ({self.steps_below_threshold}/{self.patience} steps)\")\n","\n","                # Save checkpoint when first reaching below threshold\n","                if not self.best_checkpoint_saved:\n","                    print(f\"ðŸ’¾ Saving checkpoint at loss {current_loss:.4f}\")\n","                    control.should_save = True\n","                    self.best_checkpoint_saved = True\n","\n","                # Stop training if stayed below threshold for patience steps\n","                if self.auto_stop and self.steps_below_threshold >= self.patience:\n","                    print(f\"\\nðŸ›‘ Stopping training! Loss has been below {self.target_loss_threshold} for {self.patience} steps.\")\n","                    print(f\"Final loss: {current_loss:.4f}\")\n","                    control.should_training_stop = True\n","            else:\n","                self.steps_below_threshold = 0\n","\n","        return control"]},{"cell_type":"code","execution_count":null,"id":"a4d1009f-873c-4906-a9e5-07cfc9c0cb1c","metadata":{"id":"a4d1009f-873c-4906-a9e5-07cfc9c0cb1c"},"outputs":[],"source":["def create_prompt(instruction, input_text):\n","    \"\"\"Format the instruction and input into a prompt\"\"\"\n","    if input_text:\n","        return f\"{instruction}\\n\\n{input_text}\"\n","    return instruction\n","\n","def load_and_format_dataset(file_path, train_split=0.8, output_dir=\"data\", max_samples=None):\n","    \"\"\"Improved dataset preparation with optional sample limit\"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","    df = pd.read_csv(file_path)\n","\n","    # Validate and filter\n","    required_columns = [\"instruction\", \"input\", \"output\"]\n","    if not all(col in df.columns for col in required_columns):\n","        raise ValueError(f\"Dataset must contain {required_columns} columns\")\n","    df = df[df[\"input\"] != \"No structured clinical data available.\"]\n","\n","    # Optional: limit dataset size for faster training/testing\n","    if max_samples and len(df) > max_samples:\n","        df = df.sample(n=max_samples, random_state=42)\n","        print(f\"Using {max_samples} samples for faster training\")\n","\n","    formatted_data = []\n","    for _, row in df.iterrows():\n","        # Create chat format\n","        user_msg = create_prompt(row[\"instruction\"], row[\"input\"])\n","        assistant_msg = row[\"output\"]\n","\n","        # Create both formats\n","        formatted_data.append({\n","            \"messages\": [\n","                {\"role\": \"user\", \"content\": user_msg},\n","                {\"role\": \"assistant\", \"content\": assistant_msg}\n","            ],\n","            \"text\": f\"### User: {user_msg} ###\\n### Assistant: {assistant_msg} ###\"\n","        })\n","\n","    # Split and save\n","    train_size = int(len(formatted_data) * train_split)\n","    for split, data in [(\"train\", formatted_data[:train_size]),\n","                       (\"validation\", formatted_data[train_size:])]:\n","        with open(os.path.join(output_dir, f\"{split}.jsonl\"), \"w\") as f:\n","            for item in data:\n","                json.dump(item, f)\n","                f.write(\"\\n\")\n","\n","    print(f\"Saved {train_size} training and {len(formatted_data)-train_size} validation examples\")\n","    return load_dataset(\"json\", data_files={\n","        \"train\": os.path.join(output_dir, \"train.jsonl\"),\n","        \"validation\": os.path.join(output_dir, \"validation.jsonl\")\n","    })"]},{"cell_type":"code","execution_count":null,"id":"a1fbbbc2-616e-430e-a6da-842e8b3ba33c","metadata":{"id":"a1fbbbc2-616e-430e-a6da-842e8b3ba33c"},"outputs":[],"source":["def preprocess_and_save_dataset(dataset, tokenizer, output_dir=\"preprocessed_data\"):\n","    \"\"\"Pre-tokenize and cache dataset\"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","    def tokenize_function(example):\n","        return tokenizer(example[\"text\"], truncation=True, max_length=512)  # 512 is good balance\n","    tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"messages\", \"text\"])\n","    tokenized_dataset.save_to_disk(output_dir)\n","    return tokenized_dataset\n","\n","def configure_qlora_model(model_name=\"medalpaca/medalpaca-7b\"):\n","    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n","    if tokenizer.pad_token is None:\n","        tokenizer.pad_token = tokenizer.eos_token\n","\n","    bnb_config = BitsAndBytesConfig(\n","        load_in_4bit=True,\n","        bnb_4bit_quant_type=\"nf4\",\n","        bnb_4bit_compute_dtype=torch.float16,\n","        bnb_4bit_use_double_quant=False\n","    )\n","\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_name,\n","        quantization_config=bnb_config,\n","        device_map=\"auto\",\n","        dtype=torch.float16,\n","        trust_remote_code=True\n","    )\n","    model.config.pad_token_id = tokenizer.eos_token_id\n","    model = prepare_model_for_kbit_training(model)\n","\n","    lora_config = LoraConfig(\n","        r=4,  # Reduced from 8\n","        lora_alpha=8,  # Reduced from 16\n","        lora_dropout=0.05,\n","        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n","        bias=\"none\",\n","        task_type=\"CAUSAL_LM\",\n","        inference_mode=False,\n","        fan_in_fan_out=False,\n","        modules_to_save=[\"embed_tokens\", \"lm_head\"]\n","    )\n","\n","    print(\"Applying PEFT adapters to the model...\")\n","    peft_model = get_peft_model(model, lora_config)\n","    print(f\"[DEBUG] Type after get_peft_model: {type(peft_model)}\")\n","\n","    if not isinstance(peft_model, (PeftModel, PeftModelForCausalLM)):\n","        raise ValueError(\"Model is not a PEFT model instance!\")\n","    else:\n","        print(\"[OK] Model wrapped with PEFT successfully.\")\n","\n","    print(peft_model.print_trainable_parameters())\n","\n","    for name, param in peft_model.named_parameters():\n","        if 'lora' in name:\n","            param.requires_grad = True\n","\n","    return peft_model, tokenizer"]},{"cell_type":"code","execution_count":null,"id":"OaugQ4lH0sJg","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OaugQ4lH0sJg","outputId":"729ba59c-92af-41e7-ecdc-6e3c1876e9ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["whoami: {'type': 'user', 'id': '67a65f47497698c82022ada1', 'name': 'AparnaSuresh', 'fullname': 'AparnaSuresh', 'isPro': False, 'avatarUrl': '/avatars/6fcc5210516443950f310cdd623057d8.svg', 'orgs': [], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'Project', 'role': 'fineGrained', 'createdAt': '2025-10-27T23:01:22.527Z', 'fineGrained': {'canReadGatedRepos': True, 'global': ['discussion.write', 'post.write'], 'scoped': [{'entity': {'_id': '661f97d48e7f3438386f755d', 'type': 'model', 'name': 'meta-llama/Meta-Llama-3-8B'}, 'permissions': ['repo.content.read', 'discussion.write']}, {'entity': {'_id': '67a65f47497698c82022ada1', 'type': 'user', 'name': 'AparnaSuresh'}, 'permissions': ['repo.content.read', 'repo.write', 'inference.serverless.write', 'inference.endpoints.infer.write', 'inference.endpoints.write', 'user.webhooks.read', 'user.webhooks.write', 'collection.read', 'collection.write', 'discussion.write', 'job.write']}]}}}}\n","8cde5ca8380496c9a6cc7ef3a8b46a0372a1d920\n"]}],"source":["import os\n","from huggingface_hub import login, HfApi, whoami\n","\n","# 1) put your NEW token here (donâ€™t share it)\n","os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = \"HF_TOKEN_FROM_ENV\"\n","\n","# 2) login so the credential is cached\n","login(os.environ[\"HUGGINGFACE_HUB_TOKEN\"])\n","\n","# 3) sanity checks\n","print(\"whoami:\", whoami())\n","api = HfApi()\n","# This will raise 401 (not authed) or 403 (no access) if something's off\n","print(api.model_info(\"meta-llama/Meta-Llama-3-8B\", token=os.environ[\"HUGGINGFACE_HUB_TOKEN\"]).sha)"]},{"cell_type":"code","execution_count":null,"id":"3897ae90-7d4b-4ba1-acb1-bd405582debd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":699,"referenced_widgets":["b2e2b96ec57b467c9823fb216424bcd3","61399a20b820409491e41d6112c7a469","2cc305f5bd88457ea8a020b38ebcd037","8e325292c0544621b215ba471ea76c86","fe1754166d234430afd2fad70cbb943d","8396384996a9429584d1a770bbd04ebe","59352ca976c146128d1c81d59470b1dd","d23fbfaeae004b6383a79f64d171403f","5874890f49b84594a94fe34c5f2afe98","1c261dc893894eab9f7fe791f68022dc","642a1075ae2b488d97748eaa27d97ae3","ffb68d6bdbba4db19831d1d6183fdc3e","058e301b87dd4177b6b0c24b93884c90","82751a0bdf534629a63f20cc60b6c4c5","ad4b2837f101433c8b1eb9e6689f9e69","8d8471641f4543b09a2d0eaa61b95066","1936a1bd1369453b83ad8d582ae01619","6c3cdbc7354b47dea11f85a6ad34b02e","d9afd6d0156549c789406d449c16325e","ecfab6c9fab345f78225f6721ec68888","3a8217b1afbe4bae9e4aa0d06656dae2","8fd8bcdc8de443e1b4f4df811cc437ab","c340f53d926c46b9aa07efb8420a7076","15fd060eb21e43d7b27b757dc09f51b4","cae8934db0e34374bd98e33d910971f4","b35af9be1d36423b9831635c584392ff","d8254b8011f64977b328d3d498cb5b40","f396680277314b0c975fea03ae2e9c91","0e0c243d319e41868d2bf432324b93e8","8332280cc26d4671a711005353b05216","cf19364c08d94571a7fea9a4d018cc01","6204dffe6e9642448a05d767794495de","3fc9b0e2c1b34b259ffdd4c5f1dc5282","cae4909e0c754d1ea576ec0ac3f9f5ef","a15ae7aae4ba4806b296e15f4559091c","3646cc18ce4b4fe58c191f63f7b92fcb","10644c83b86d4188af054097e677eee8","e8530c7689df4f968d475a1533b57f6a","9de34c43970147f08d2f4be1bc0a7043","a3e40221fb5c49b5801f47ba2cd668fe","fe709d095cf4400a9b6a987f32731888","0352a2da920a47b38208abbf227a38e1","4a46d6bd329748048b08cffec15386e8","ba355c4ef362474fb97aa0163a322921","816fa6e9e41b469ebfdf4b86d2670a4b","bfd39638019645df9852446420eedb12","2fb053ee95454ee59c0f443cea47954f","d263477398fa43eea722a6cd05af442f","1dd29a12f91644dfbe6326ba6f1a30d3","ad16e5682c9948bd933c373be9706f27","401c4e817e114920a70a6d82ca19b935","0c6d271ffebe4c8abc0ebf3b3aa1b843","45801b226a2442648bd75dd1bad6ba24","6184e29664cd473b94f38fe38d97f470","d8f6cfd471e545a3bd5058ff31f7680d","bc9a2a496ef741309780f986b092cf74","362ea8fa35d841c48e9597b5a33dfd56","4b45e931031e46f98ba1a8f84ffef97b","65539231f64d461bae768c8f051c0d5f","858dd835c2b94b64afbb7a989a91eb70","9c33246c98f84d6a9e2dce1cdb068d72","8a4bc6ad4dc54202a714d9683c41dca3","5f973ae5462e44bfa14500918fd0e488","dd3c5a45df164571b19f9591af8bb841","83264cc56e2642be84fea1bad362f334","068296ebafd647fd962b7c5c0ccc890e","87a5f2c3506645558d6372420dbb0156","2e19a37424af4b5c92eb81e74e3ef54e","84c00a8e95d04437a97ec0669d4aad0e","bdeba484286445ce8182f7f37c210d8e","24ca02abf79e4104ba25f3e5bb156c40","2f1bc70f71cd462e807f669d8eef1231","db41eaa736a843918aafb1146c8db992","3d93b8ca94b74a10afe25e16b4976156","8adff43f4a854025b77b63ad15ae6913","514c9073a0924d1688941e6fc45d7919","20d50db6a28f4864a742bcf858f2ec14","486d1eec91014e6e9c70bada113f5000","3c279af50bea4ff6b276cafaff6c4ad4","6174496dbff247a79d8f0051e14d7fe4","d1fe9762ed9246b3a17aae5c8e4f6ee3","8ca11a7e1f0b4f73bfcc7af47dae9fdc","c2d71b8af20b4b3e926966ccecc8e437","96b2c05ac8b24107ba66cb9adcf4e32d","9bd79c878db743f5bf13c26524339115","5f8c41d11abf4a169acd7936a21f2021","5e15424cec4e4f7ea2a81445520963df","5c9e7941b1a14233918ba3d6235c517d","6aeb49e27b014c26b9f2a8c062904f08","be8eb938d9f34eb7b9b8875274d6a49f","dad80ce2460c4021914104976f7e572c","a9f90d048e744421a42e436bfc70e5e6","cf287b73a2374305acc7550a87bf330c","2c4af94ea4eb4306a5b36eaf287f6cd6","62b5b4e5e5bf448685b507f8bdd4b38a","c8c601c647524c7daeaf0330771dbcd6","09715f8262ec4125b7a7280253e595dd","2c100069c794484fa312c438dac3c6a7","1ff58958a21f4ea39ce9ee1384689417","c21bc9d9a6e34ea7b762f519ae5db8d1","c3e327b5f82341e8a95eda48212e02f3","1e8b9c13ccba4bd198124df85d2d93b2","beba5d5115064a37b7acd4a380477d4a","ebe10c4d3ab249d08682bceeb122d8ab","17b4f0a795a148c88ec72f316956d7ef","98cc623bb4614e83a6dbe045934ad5b6","7e741203ce874a8d942ce883a12081bf","ec7c0ffc757643f3bceeff247e313659","0086927e6fb84e308044fabd668cbd82","724ed8ce60124943ab0f55363390f681","2ad974a24dbb4ee494d757f024843b71","57e1b5b822a24bd59ba65315a8ca565c","365aa4ec1564439aad5905f5b0b4bb61","b8916dae11054127b727dee91ba276f1","ef34db0be4404c4aae5af7e413884e1e","8dd7d60afc5545f29350ca66a0fe0ea1","22bdcac3acf842518978ed21da264c34","0286b2875f7a4461851599cba6961bc7","7594d9377d634f2fa0561a25f27032a6","cfb83bbe6f104654a3c1ae9167376466","1f513381788b46f18c5833d5f2d9ec25","2e742995e5254542b77c7008db585c4f","c0b8842934c64ab08b4934ed49dfa9b2","8d90135affa94524897b8a79961e40d0","d63e5d8295ac44ff97cbaeb20a4f72fe","aac2d5ddb28042458d0aaabd436cd380","a2bbe3de651a4d8289e89d13ec241965","b2fc86f28d4542069c7513526721dfbd","eb0131ef72d8472a9f0e59e42f82df7e","84ee44d25b2348fe84f84cff5f71ba8a","752ab4def4cb49dd8f484eeedd72c461","ba659b545eb343a1a117eb6dd0dbadaf"]},"id":"3897ae90-7d4b-4ba1-acb1-bd405582debd","outputId":"22d914aa-8de8-40f8-b921-d68f9e7fa2c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading and preparing dataset...\n","Saved 89530 training and 22383 validation examples\n"]},{"name":"stderr","output_type":"stream","text":["Generating train split: 89530 examples [00:00, 132003.32 examples/s]\n","Generating validation split: 22383 examples [00:00, 85046.32 examples/s]\n"]},{"name":"stdout","output_type":"stream","text":["Dataset loaded: DatasetDict({\n","    train: Dataset({\n","        features: ['messages', 'text'],\n","        num_rows: 89530\n","    })\n","    validation: Dataset({\n","        features: ['messages', 'text'],\n","        num_rows: 22383\n","    })\n","})\n","Loading tokenizer...\n","Preprocessing and tokenizing dataset...\n"]},{"name":"stderr","output_type":"stream","text":["Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89530/89530 [01:00<00:00, 1486.94 examples/s]\n","Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22383/22383 [00:23<00:00, 939.72 examples/s]\n","Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89530/89530 [00:00<00:00, 181804.64 examples/s]\n","Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22383/22383 [00:00<00:00, 127663.74 examples/s]\n"]},{"name":"stdout","output_type":"stream","text":["Preprocessed dataset: DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask'],\n","        num_rows: 89530\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'attention_mask'],\n","        num_rows: 22383\n","    })\n","})\n","Configuring QLoRA model...\n"]},{"name":"stderr","output_type":"stream","text":["Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:10<00:00,  3.57s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Applying PEFT adapters to the model...\n"]},{"name":"stderr","output_type":"stream","text":["You passed a dataset that is already processed (contains an `input_ids` field) together with a formatting function. Therefore `formatting_func` will be ignored. Either remove the `formatting_func` or pass a dataset that is not already processed.\n"]},{"name":"stdout","output_type":"stream","text":["[DEBUG] Type after get_peft_model: <class 'peft.peft_model.PeftModelForCausalLM'>\n","[OK] Model wrapped with PEFT successfully.\n","trainable params: 272,146,432 || all params: 7,010,570,240 || trainable%: 3.8819\n","None\n","QLoRA model configured successfully!\n","Setting up trainer...\n","Model is a PEFT model: True\n","ðŸ“Š Using NVIDIA GeForce RTX 5090. Standard GPU settings applied.\n","âœ… Training config: Batch size=8, Gradient accum=2, Workers=4\n","Creating SFTTrainer with EarlyStoppingOnLoss callback...\n","ðŸ“Š Will monitor loss and save checkpoint when it drops below 0.1\n","ðŸ›‘ Auto-stop enabled: Training will stop after 50 steps below threshold\n"]},{"name":"stderr","output_type":"stream","text":["Truncating train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89530/89530 [00:00<00:00, 823483.83 examples/s]\n","The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 2, 'pad_token_id': 32000}.\n","The model is already on multiple devices. Skipping the move to device specified in `args`.\n"]},{"name":"stdout","output_type":"stream","text":["Trainer configured successfully!\n","Starting training...\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='11192' max='11192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [11192/11192 5:34:53, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>2.085100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.300000</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.127200</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.104000</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.042300</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.031700</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.011100</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.984900</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.991600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.976200</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.966100</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.942900</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.923300</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.906500</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.949400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.936100</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.931800</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.934700</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.899100</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.922000</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.932200</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.897600</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.919900</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.928300</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.889700</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.858600</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.888900</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.872800</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.895100</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.880900</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.880500</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.899800</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.866500</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.852800</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.875500</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.864100</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.876800</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.885300</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.828200</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.881000</td>\n","    </tr>\n","    <tr>\n","      <td>2050</td>\n","      <td>0.839600</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.860100</td>\n","    </tr>\n","    <tr>\n","      <td>2150</td>\n","      <td>0.881700</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.840500</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.865600</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>0.847700</td>\n","    </tr>\n","    <tr>\n","      <td>2350</td>\n","      <td>0.841200</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.828900</td>\n","    </tr>\n","    <tr>\n","      <td>2450</td>\n","      <td>0.819200</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.824900</td>\n","    </tr>\n","    <tr>\n","      <td>2550</td>\n","      <td>0.844400</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.830600</td>\n","    </tr>\n","    <tr>\n","      <td>2650</td>\n","      <td>0.850100</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>0.864100</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.864100</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.821600</td>\n","    </tr>\n","    <tr>\n","      <td>2850</td>\n","      <td>0.842000</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>0.825400</td>\n","    </tr>\n","    <tr>\n","      <td>2950</td>\n","      <td>0.833900</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.811100</td>\n","    </tr>\n","    <tr>\n","      <td>3050</td>\n","      <td>0.800800</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>0.847800</td>\n","    </tr>\n","    <tr>\n","      <td>3150</td>\n","      <td>0.821700</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.825900</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>0.830000</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>0.826100</td>\n","    </tr>\n","    <tr>\n","      <td>3350</td>\n","      <td>0.857900</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>0.849600</td>\n","    </tr>\n","    <tr>\n","      <td>3450</td>\n","      <td>0.791100</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.814100</td>\n","    </tr>\n","    <tr>\n","      <td>3550</td>\n","      <td>0.796800</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.837000</td>\n","    </tr>\n","    <tr>\n","      <td>3650</td>\n","      <td>0.828300</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>0.800400</td>\n","    </tr>\n","    <tr>\n","      <td>3750</td>\n","      <td>0.802500</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>0.785000</td>\n","    </tr>\n","    <tr>\n","      <td>3850</td>\n","      <td>0.768100</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>0.808000</td>\n","    </tr>\n","    <tr>\n","      <td>3950</td>\n","      <td>0.815900</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.825100</td>\n","    </tr>\n","    <tr>\n","      <td>4050</td>\n","      <td>0.783700</td>\n","    </tr>\n","    <tr>\n","      <td>4100</td>\n","      <td>0.802400</td>\n","    </tr>\n","    <tr>\n","      <td>4150</td>\n","      <td>0.802000</td>\n","    </tr>\n","    <tr>\n","      <td>4200</td>\n","      <td>0.761900</td>\n","    </tr>\n","    <tr>\n","      <td>4250</td>\n","      <td>0.795200</td>\n","    </tr>\n","    <tr>\n","      <td>4300</td>\n","      <td>0.780800</td>\n","    </tr>\n","    <tr>\n","      <td>4350</td>\n","      <td>0.783800</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>0.794000</td>\n","    </tr>\n","    <tr>\n","      <td>4450</td>\n","      <td>0.833200</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.797400</td>\n","    </tr>\n","    <tr>\n","      <td>4550</td>\n","      <td>0.786300</td>\n","    </tr>\n","    <tr>\n","      <td>4600</td>\n","      <td>0.805600</td>\n","    </tr>\n","    <tr>\n","      <td>4650</td>\n","      <td>0.805800</td>\n","    </tr>\n","    <tr>\n","      <td>4700</td>\n","      <td>0.786700</td>\n","    </tr>\n","    <tr>\n","      <td>4750</td>\n","      <td>0.746700</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>0.806700</td>\n","    </tr>\n","    <tr>\n","      <td>4850</td>\n","      <td>0.773900</td>\n","    </tr>\n","    <tr>\n","      <td>4900</td>\n","      <td>0.776200</td>\n","    </tr>\n","    <tr>\n","      <td>4950</td>\n","      <td>0.778700</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.766600</td>\n","    </tr>\n","    <tr>\n","      <td>5050</td>\n","      <td>0.771300</td>\n","    </tr>\n","    <tr>\n","      <td>5100</td>\n","      <td>0.787300</td>\n","    </tr>\n","    <tr>\n","      <td>5150</td>\n","      <td>0.798200</td>\n","    </tr>\n","    <tr>\n","      <td>5200</td>\n","      <td>0.745700</td>\n","    </tr>\n","    <tr>\n","      <td>5250</td>\n","      <td>0.780600</td>\n","    </tr>\n","    <tr>\n","      <td>5300</td>\n","      <td>0.757000</td>\n","    </tr>\n","    <tr>\n","      <td>5350</td>\n","      <td>0.793300</td>\n","    </tr>\n","    <tr>\n","      <td>5400</td>\n","      <td>0.756800</td>\n","    </tr>\n","    <tr>\n","      <td>5450</td>\n","      <td>0.775600</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.786500</td>\n","    </tr>\n","    <tr>\n","      <td>5550</td>\n","      <td>0.792200</td>\n","    </tr>\n","    <tr>\n","      <td>5600</td>\n","      <td>0.803900</td>\n","    </tr>\n","    <tr>\n","      <td>5650</td>\n","      <td>0.749500</td>\n","    </tr>\n","    <tr>\n","      <td>5700</td>\n","      <td>0.710900</td>\n","    </tr>\n","    <tr>\n","      <td>5750</td>\n","      <td>0.704300</td>\n","    </tr>\n","    <tr>\n","      <td>5800</td>\n","      <td>0.721100</td>\n","    </tr>\n","    <tr>\n","      <td>5850</td>\n","      <td>0.702600</td>\n","    </tr>\n","    <tr>\n","      <td>5900</td>\n","      <td>0.722800</td>\n","    </tr>\n","    <tr>\n","      <td>5950</td>\n","      <td>0.701900</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.737400</td>\n","    </tr>\n","    <tr>\n","      <td>6050</td>\n","      <td>0.726700</td>\n","    </tr>\n","    <tr>\n","      <td>6100</td>\n","      <td>0.702200</td>\n","    </tr>\n","    <tr>\n","      <td>6150</td>\n","      <td>0.746400</td>\n","    </tr>\n","    <tr>\n","      <td>6200</td>\n","      <td>0.697500</td>\n","    </tr>\n","    <tr>\n","      <td>6250</td>\n","      <td>0.717300</td>\n","    </tr>\n","    <tr>\n","      <td>6300</td>\n","      <td>0.715700</td>\n","    </tr>\n","    <tr>\n","      <td>6350</td>\n","      <td>0.693600</td>\n","    </tr>\n","    <tr>\n","      <td>6400</td>\n","      <td>0.736000</td>\n","    </tr>\n","    <tr>\n","      <td>6450</td>\n","      <td>0.715100</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.731100</td>\n","    </tr>\n","    <tr>\n","      <td>6550</td>\n","      <td>0.695400</td>\n","    </tr>\n","    <tr>\n","      <td>6600</td>\n","      <td>0.697300</td>\n","    </tr>\n","    <tr>\n","      <td>6650</td>\n","      <td>0.715400</td>\n","    </tr>\n","    <tr>\n","      <td>6700</td>\n","      <td>0.717700</td>\n","    </tr>\n","    <tr>\n","      <td>6750</td>\n","      <td>0.678200</td>\n","    </tr>\n","    <tr>\n","      <td>6800</td>\n","      <td>0.707500</td>\n","    </tr>\n","    <tr>\n","      <td>6850</td>\n","      <td>0.692400</td>\n","    </tr>\n","    <tr>\n","      <td>6900</td>\n","      <td>0.731300</td>\n","    </tr>\n","    <tr>\n","      <td>6950</td>\n","      <td>0.719300</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.698900</td>\n","    </tr>\n","    <tr>\n","      <td>7050</td>\n","      <td>0.732300</td>\n","    </tr>\n","    <tr>\n","      <td>7100</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>7150</td>\n","      <td>0.691900</td>\n","    </tr>\n","    <tr>\n","      <td>7200</td>\n","      <td>0.715900</td>\n","    </tr>\n","    <tr>\n","      <td>7250</td>\n","      <td>0.688800</td>\n","    </tr>\n","    <tr>\n","      <td>7300</td>\n","      <td>0.718700</td>\n","    </tr>\n","    <tr>\n","      <td>7350</td>\n","      <td>0.695900</td>\n","    </tr>\n","    <tr>\n","      <td>7400</td>\n","      <td>0.682700</td>\n","    </tr>\n","    <tr>\n","      <td>7450</td>\n","      <td>0.689800</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.722700</td>\n","    </tr>\n","    <tr>\n","      <td>7550</td>\n","      <td>0.707300</td>\n","    </tr>\n","    <tr>\n","      <td>7600</td>\n","      <td>0.702500</td>\n","    </tr>\n","    <tr>\n","      <td>7650</td>\n","      <td>0.706800</td>\n","    </tr>\n","    <tr>\n","      <td>7700</td>\n","      <td>0.703500</td>\n","    </tr>\n","    <tr>\n","      <td>7750</td>\n","      <td>0.703200</td>\n","    </tr>\n","    <tr>\n","      <td>7800</td>\n","      <td>0.683100</td>\n","    </tr>\n","    <tr>\n","      <td>7850</td>\n","      <td>0.700500</td>\n","    </tr>\n","    <tr>\n","      <td>7900</td>\n","      <td>0.707000</td>\n","    </tr>\n","    <tr>\n","      <td>7950</td>\n","      <td>0.713800</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.698500</td>\n","    </tr>\n","    <tr>\n","      <td>8050</td>\n","      <td>0.726100</td>\n","    </tr>\n","    <tr>\n","      <td>8100</td>\n","      <td>0.710100</td>\n","    </tr>\n","    <tr>\n","      <td>8150</td>\n","      <td>0.700300</td>\n","    </tr>\n","    <tr>\n","      <td>8200</td>\n","      <td>0.702700</td>\n","    </tr>\n","    <tr>\n","      <td>8250</td>\n","      <td>0.689700</td>\n","    </tr>\n","    <tr>\n","      <td>8300</td>\n","      <td>0.722100</td>\n","    </tr>\n","    <tr>\n","      <td>8350</td>\n","      <td>0.708600</td>\n","    </tr>\n","    <tr>\n","      <td>8400</td>\n","      <td>0.677900</td>\n","    </tr>\n","    <tr>\n","      <td>8450</td>\n","      <td>0.687000</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.687900</td>\n","    </tr>\n","    <tr>\n","      <td>8550</td>\n","      <td>0.680200</td>\n","    </tr>\n","    <tr>\n","      <td>8600</td>\n","      <td>0.680000</td>\n","    </tr>\n","    <tr>\n","      <td>8650</td>\n","      <td>0.682500</td>\n","    </tr>\n","    <tr>\n","      <td>8700</td>\n","      <td>0.673500</td>\n","    </tr>\n","    <tr>\n","      <td>8750</td>\n","      <td>0.699300</td>\n","    </tr>\n","    <tr>\n","      <td>8800</td>\n","      <td>0.745000</td>\n","    </tr>\n","    <tr>\n","      <td>8850</td>\n","      <td>0.687000</td>\n","    </tr>\n","    <tr>\n","      <td>8900</td>\n","      <td>0.703200</td>\n","    </tr>\n","    <tr>\n","      <td>8950</td>\n","      <td>0.688900</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.694400</td>\n","    </tr>\n","    <tr>\n","      <td>9050</td>\n","      <td>0.685900</td>\n","    </tr>\n","    <tr>\n","      <td>9100</td>\n","      <td>0.682900</td>\n","    </tr>\n","    <tr>\n","      <td>9150</td>\n","      <td>0.681400</td>\n","    </tr>\n","    <tr>\n","      <td>9200</td>\n","      <td>0.658900</td>\n","    </tr>\n","    <tr>\n","      <td>9250</td>\n","      <td>0.660400</td>\n","    </tr>\n","    <tr>\n","      <td>9300</td>\n","      <td>0.721300</td>\n","    </tr>\n","    <tr>\n","      <td>9350</td>\n","      <td>0.691900</td>\n","    </tr>\n","    <tr>\n","      <td>9400</td>\n","      <td>0.688100</td>\n","    </tr>\n","    <tr>\n","      <td>9450</td>\n","      <td>0.705600</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.682300</td>\n","    </tr>\n","    <tr>\n","      <td>9550</td>\n","      <td>0.681700</td>\n","    </tr>\n","    <tr>\n","      <td>9600</td>\n","      <td>0.701500</td>\n","    </tr>\n","    <tr>\n","      <td>9650</td>\n","      <td>0.720800</td>\n","    </tr>\n","    <tr>\n","      <td>9700</td>\n","      <td>0.691000</td>\n","    </tr>\n","    <tr>\n","      <td>9750</td>\n","      <td>0.716100</td>\n","    </tr>\n","    <tr>\n","      <td>9800</td>\n","      <td>0.685900</td>\n","    </tr>\n","    <tr>\n","      <td>9850</td>\n","      <td>0.699300</td>\n","    </tr>\n","    <tr>\n","      <td>9900</td>\n","      <td>0.681700</td>\n","    </tr>\n","    <tr>\n","      <td>9950</td>\n","      <td>0.708200</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.665900</td>\n","    </tr>\n","    <tr>\n","      <td>10050</td>\n","      <td>0.681500</td>\n","    </tr>\n","    <tr>\n","      <td>10100</td>\n","      <td>0.664300</td>\n","    </tr>\n","    <tr>\n","      <td>10150</td>\n","      <td>0.681800</td>\n","    </tr>\n","    <tr>\n","      <td>10200</td>\n","      <td>0.652300</td>\n","    </tr>\n","    <tr>\n","      <td>10250</td>\n","      <td>0.720800</td>\n","    </tr>\n","    <tr>\n","      <td>10300</td>\n","      <td>0.685600</td>\n","    </tr>\n","    <tr>\n","      <td>10350</td>\n","      <td>0.685600</td>\n","    </tr>\n","    <tr>\n","      <td>10400</td>\n","      <td>0.727000</td>\n","    </tr>\n","    <tr>\n","      <td>10450</td>\n","      <td>0.693200</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.684300</td>\n","    </tr>\n","    <tr>\n","      <td>10550</td>\n","      <td>0.694900</td>\n","    </tr>\n","    <tr>\n","      <td>10600</td>\n","      <td>0.679500</td>\n","    </tr>\n","    <tr>\n","      <td>10650</td>\n","      <td>0.666600</td>\n","    </tr>\n","    <tr>\n","      <td>10700</td>\n","      <td>0.697500</td>\n","    </tr>\n","    <tr>\n","      <td>10750</td>\n","      <td>0.652400</td>\n","    </tr>\n","    <tr>\n","      <td>10800</td>\n","      <td>0.691000</td>\n","    </tr>\n","    <tr>\n","      <td>10850</td>\n","      <td>0.713600</td>\n","    </tr>\n","    <tr>\n","      <td>10900</td>\n","      <td>0.701200</td>\n","    </tr>\n","    <tr>\n","      <td>10950</td>\n","      <td>0.676400</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.678500</td>\n","    </tr>\n","    <tr>\n","      <td>11050</td>\n","      <td>0.709300</td>\n","    </tr>\n","    <tr>\n","      <td>11100</td>\n","      <td>0.706300</td>\n","    </tr>\n","    <tr>\n","      <td>11150</td>\n","      <td>0.671600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","[Step 50] Current Loss: 2.0851\n","\n","[Step 100] Current Loss: 1.3000\n","\n","[Step 150] Current Loss: 1.1272\n","\n","[Step 200] Current Loss: 1.1040\n","\n","[Step 250] Current Loss: 1.0423\n","\n","[Step 300] Current Loss: 1.0317\n","\n","[Step 350] Current Loss: 1.0111\n","\n","[Step 400] Current Loss: 0.9849\n","\n","[Step 450] Current Loss: 0.9916\n","\n","[Step 500] Current Loss: 0.9762\n","\n","[Step 550] Current Loss: 0.9661\n","\n","[Step 600] Current Loss: 0.9429\n","\n","[Step 650] Current Loss: 0.9233\n","\n","[Step 700] Current Loss: 0.9065\n","\n","[Step 750] Current Loss: 0.9494\n","\n","[Step 800] Current Loss: 0.9361\n","\n","[Step 850] Current Loss: 0.9318\n","\n","[Step 900] Current Loss: 0.9347\n","\n","[Step 950] Current Loss: 0.8991\n","\n","[Step 1000] Current Loss: 0.9220\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\n","[Step 1050] Current Loss: 0.9322\n","\n","[Step 1100] Current Loss: 0.8976\n","\n","[Step 1150] Current Loss: 0.9199\n","\n","[Step 1200] Current Loss: 0.9283\n","\n","[Step 1250] Current Loss: 0.8897\n","\n","[Step 1300] Current Loss: 0.8586\n","\n","[Step 1350] Current Loss: 0.8889\n","\n","[Step 1400] Current Loss: 0.8728\n","\n","[Step 1450] Current Loss: 0.8951\n","\n","[Step 1500] Current Loss: 0.8809\n","\n","[Step 1550] Current Loss: 0.8805\n","\n","[Step 1600] Current Loss: 0.8998\n","\n","[Step 1650] Current Loss: 0.8665\n","\n","[Step 1700] Current Loss: 0.8528\n","\n","[Step 1750] Current Loss: 0.8755\n","\n","[Step 1800] Current Loss: 0.8641\n","\n","[Step 1850] Current Loss: 0.8768\n","\n","[Step 1900] Current Loss: 0.8853\n","\n","[Step 1950] Current Loss: 0.8282\n","\n","[Step 2000] Current Loss: 0.8810\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\n","[Step 2050] Current Loss: 0.8396\n","\n","[Step 2100] Current Loss: 0.8601\n","\n","[Step 2150] Current Loss: 0.8817\n","\n","[Step 2200] Current Loss: 0.8405\n","\n","[Step 2250] Current Loss: 0.8656\n","\n","[Step 2300] Current Loss: 0.8477\n","\n","[Step 2350] Current Loss: 0.8412\n","\n","[Step 2400] Current Loss: 0.8289\n","\n","[Step 2450] Current Loss: 0.8192\n","\n","[Step 2500] Current Loss: 0.8249\n","\n","[Step 2550] Current Loss: 0.8444\n","\n","[Step 2600] Current Loss: 0.8306\n","\n","[Step 2650] Current Loss: 0.8501\n","\n","[Step 2700] Current Loss: 0.8641\n","\n","[Step 2750] Current Loss: 0.8641\n","\n","[Step 2800] Current Loss: 0.8216\n","\n","[Step 2850] Current Loss: 0.8420\n","\n","[Step 2900] Current Loss: 0.8254\n","\n","[Step 2950] Current Loss: 0.8339\n","\n","[Step 3000] Current Loss: 0.8111\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\n","[Step 3050] Current Loss: 0.8008\n","\n","[Step 3100] Current Loss: 0.8478\n","\n","[Step 3150] Current Loss: 0.8217\n","\n","[Step 3200] Current Loss: 0.8259\n","\n","[Step 3250] Current Loss: 0.8300\n","\n","[Step 3300] Current Loss: 0.8261\n","\n","[Step 3350] Current Loss: 0.8579\n","\n","[Step 3400] Current Loss: 0.8496\n","\n","[Step 3450] Current Loss: 0.7911\n","\n","[Step 3500] Current Loss: 0.8141\n","\n","[Step 3550] Current Loss: 0.7968\n","\n","[Step 3600] Current Loss: 0.8370\n","\n","[Step 3650] Current Loss: 0.8283\n","\n","[Step 3700] Current Loss: 0.8004\n","\n","[Step 3750] Current Loss: 0.8025\n","\n","[Step 3800] Current Loss: 0.7850\n","\n","[Step 3850] Current Loss: 0.7681\n","\n","[Step 3900] Current Loss: 0.8080\n","\n","[Step 3950] Current Loss: 0.8159\n","\n","[Step 4000] Current Loss: 0.8251\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\n","[Step 4050] Current Loss: 0.7837\n","\n","[Step 4100] Current Loss: 0.8024\n","\n","[Step 4150] Current Loss: 0.8020\n","\n","[Step 4200] Current Loss: 0.7619\n","\n","[Step 4250] Current Loss: 0.7952\n","\n","[Step 4300] Current Loss: 0.7808\n","\n","[Step 4350] Current Loss: 0.7838\n","\n","[Step 4400] Current Loss: 0.7940\n","\n","[Step 4450] Current Loss: 0.8332\n","\n","[Step 4500] Current Loss: 0.7974\n","\n","[Step 4550] Current Loss: 0.7863\n","\n","[Step 4600] Current Loss: 0.8056\n","\n","[Step 4650] Current Loss: 0.8058\n","\n","[Step 4700] Current Loss: 0.7867\n","\n","[Step 4750] Current Loss: 0.7467\n","\n","[Step 4800] Current Loss: 0.8067\n","\n","[Step 4850] Current Loss: 0.7739\n","\n","[Step 4900] Current Loss: 0.7762\n","\n","[Step 4950] Current Loss: 0.7787\n","\n","[Step 5000] Current Loss: 0.7666\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\n","[Step 5050] Current Loss: 0.7713\n","\n","[Step 5100] Current Loss: 0.7873\n","\n","[Step 5150] Current Loss: 0.7982\n","\n","[Step 5200] Current Loss: 0.7457\n","\n","[Step 5250] Current Loss: 0.7806\n","\n","[Step 5300] Current Loss: 0.7570\n","\n","[Step 5350] Current Loss: 0.7933\n","\n","[Step 5400] Current Loss: 0.7568\n","\n","[Step 5450] Current Loss: 0.7756\n","\n","[Step 5500] Current Loss: 0.7865\n","\n","[Step 5550] Current Loss: 0.7922\n","\n","[Step 5600] Current Loss: 0.8039\n","\n","[Step 5650] Current Loss: 0.7495\n","\n","[Step 5700] Current Loss: 0.7109\n","\n","[Step 5750] Current Loss: 0.7043\n","\n","[Step 5800] Current Loss: 0.7211\n","\n","[Step 5850] Current Loss: 0.7026\n","\n","[Step 5900] Current Loss: 0.7228\n","\n","[Step 5950] Current Loss: 0.7019\n","\n","[Step 6000] Current Loss: 0.7374\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\n","[Step 6050] Current Loss: 0.7267\n","\n","[Step 6100] Current Loss: 0.7022\n","\n","[Step 6150] Current Loss: 0.7464\n","\n","[Step 6200] Current Loss: 0.6975\n","\n","[Step 6250] Current Loss: 0.7173\n","\n","[Step 6300] Current Loss: 0.7157\n","\n","[Step 6350] Current Loss: 0.6936\n","\n","[Step 6400] Current Loss: 0.7360\n","\n","[Step 6450] Current Loss: 0.7151\n","\n","[Step 6500] Current Loss: 0.7311\n","\n","[Step 6550] Current Loss: 0.6954\n","\n","[Step 6600] Current Loss: 0.6973\n","\n","[Step 6650] Current Loss: 0.7154\n","\n","[Step 6700] Current Loss: 0.7177\n","\n","[Step 6750] Current Loss: 0.6782\n","\n","[Step 6800] Current Loss: 0.7075\n","\n","[Step 6850] Current Loss: 0.6924\n","\n","[Step 6900] Current Loss: 0.7313\n","\n","[Step 6950] Current Loss: 0.7193\n","\n","[Step 7000] Current Loss: 0.6989\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\n","[Step 7050] Current Loss: 0.7323\n","\n","[Step 7100] Current Loss: 0.7250\n","\n","[Step 7150] Current Loss: 0.6919\n","\n","[Step 7200] Current Loss: 0.7159\n","\n","[Step 7250] Current Loss: 0.6888\n","\n","[Step 7300] Current Loss: 0.7187\n","\n","[Step 7350] Current Loss: 0.6959\n","\n","[Step 7400] Current Loss: 0.6827\n","\n","[Step 7450] Current Loss: 0.6898\n","\n","[Step 7500] Current Loss: 0.7227\n","\n","[Step 7550] Current Loss: 0.7073\n","\n","[Step 7600] Current Loss: 0.7025\n","\n","[Step 7650] Current Loss: 0.7068\n","\n","[Step 7700] Current Loss: 0.7035\n","\n","[Step 7750] Current Loss: 0.7032\n","\n","[Step 7800] Current Loss: 0.6831\n","\n","[Step 7850] Current Loss: 0.7005\n","\n","[Step 7900] Current Loss: 0.7070\n","\n","[Step 7950] Current Loss: 0.7138\n","\n","[Step 8000] Current Loss: 0.6985\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\n","[Step 8050] Current Loss: 0.7261\n","\n","[Step 8100] Current Loss: 0.7101\n","\n","[Step 8150] Current Loss: 0.7003\n","\n","[Step 8200] Current Loss: 0.7027\n","\n","[Step 8250] Current Loss: 0.6897\n","\n","[Step 8300] Current Loss: 0.7221\n","\n","[Step 8350] Current Loss: 0.7086\n","\n","[Step 8400] Current Loss: 0.6779\n","\n","[Step 8450] Current Loss: 0.6870\n","\n","[Step 8500] Current Loss: 0.6879\n","\n","[Step 8550] Current Loss: 0.6802\n","\n","[Step 8600] Current Loss: 0.6800\n","\n","[Step 8650] Current Loss: 0.6825\n","\n","[Step 8700] Current Loss: 0.6735\n","\n","[Step 8750] Current Loss: 0.6993\n","\n","[Step 8800] Current Loss: 0.7450\n","\n","[Step 8850] Current Loss: 0.6870\n","\n","[Step 8900] Current Loss: 0.7032\n","\n","[Step 8950] Current Loss: 0.6889\n","\n","[Step 9000] Current Loss: 0.6944\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\n","[Step 9050] Current Loss: 0.6859\n","\n","[Step 9100] Current Loss: 0.6829\n","\n","[Step 9150] Current Loss: 0.6814\n","\n","[Step 9200] Current Loss: 0.6589\n","\n","[Step 9250] Current Loss: 0.6604\n","\n","[Step 9300] Current Loss: 0.7213\n","\n","[Step 9350] Current Loss: 0.6919\n","\n","[Step 9400] Current Loss: 0.6881\n","\n","[Step 9450] Current Loss: 0.7056\n","\n","[Step 9500] Current Loss: 0.6823\n","\n","[Step 9550] Current Loss: 0.6817\n","\n","[Step 9600] Current Loss: 0.7015\n","\n","[Step 9650] Current Loss: 0.7208\n","\n","[Step 9700] Current Loss: 0.6910\n","\n","[Step 9750] Current Loss: 0.7161\n","\n","[Step 9800] Current Loss: 0.6859\n","\n","[Step 9850] Current Loss: 0.6993\n","\n","[Step 9900] Current Loss: 0.6817\n","\n","[Step 9950] Current Loss: 0.7082\n","\n","[Step 10000] Current Loss: 0.6659\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\n","[Step 10050] Current Loss: 0.6815\n","\n","[Step 10100] Current Loss: 0.6643\n","\n","[Step 10150] Current Loss: 0.6818\n","\n","[Step 10200] Current Loss: 0.6523\n","\n","[Step 10250] Current Loss: 0.7208\n","\n","[Step 10300] Current Loss: 0.6856\n","\n","[Step 10350] Current Loss: 0.6856\n","\n","[Step 10400] Current Loss: 0.7270\n","\n","[Step 10450] Current Loss: 0.6932\n","\n","[Step 10500] Current Loss: 0.6843\n","\n","[Step 10550] Current Loss: 0.6949\n","\n","[Step 10600] Current Loss: 0.6795\n","\n","[Step 10650] Current Loss: 0.6666\n","\n","[Step 10700] Current Loss: 0.6975\n","\n","[Step 10750] Current Loss: 0.6524\n","\n","[Step 10800] Current Loss: 0.6910\n","\n","[Step 10850] Current Loss: 0.7136\n","\n","[Step 10900] Current Loss: 0.7012\n","\n","[Step 10950] Current Loss: 0.6764\n","\n","[Step 11000] Current Loss: 0.6785\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\n","[Step 11050] Current Loss: 0.7093\n","\n","[Step 11100] Current Loss: 0.7063\n","\n","[Step 11150] Current Loss: 0.6716\n","Model trained and saved to medalpaca_finetuned\n"]}],"source":["def setup_trainer(model, tokenizer, dataset, output_dir=\"medalpaca_finetuned\"):\n","    if not isinstance(model, (PeftModel, PeftModelForCausalLM)):\n","        raise ValueError(\"Model is not a PEFT-wrapped instance! Cannot continue with training.\")\n","\n","    print(f\"Model is a PEFT model: {isinstance(model, (PeftModel, PeftModelForCausalLM))}\")\n","\n","    # Standard GPU settings (no A100-specific optimization)\n","    device_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n","    print(f\"ðŸ“Š Using {device_name}. Standard GPU settings applied.\")\n","\n","    batch_size = 8  # Standard batch size for most GPUs\n","    gradient_accum = 2  # Effective batch size = 16\n","    workers = 4\n","\n","    training_args = TrainingArguments(\n","        output_dir=output_dir,\n","        per_device_train_batch_size=batch_size,  # Auto-adjusted for GPU\n","        per_device_eval_batch_size=batch_size,\n","        gradient_accumulation_steps=gradient_accum,\n","        num_train_epochs=2,  # Increased to 2 for better training\n","        learning_rate=1e-4,  # Conservative LR to prevent overfitting\n","        bf16=True,\n","        bf16_full_eval=True,\n","        save_strategy=\"steps\",  # Save periodically during training\n","        save_steps=1000,  # Save every 1000 steps\n","        eval_strategy=\"no\",  # Disable eval during training for speed\n","        load_best_model_at_end=False,\n","        logging_steps=50,  # Log every 50 steps\n","        save_total_limit=2,  # Keep ONLY last 2 checkpoints (saves Drive space!)\n","        push_to_hub=False,\n","        gradient_checkpointing=False,  # Disabled for speed\n","        optim=\"adamw_torch_fused\",\n","        max_grad_norm=0.3,\n","        warmup_steps=100,  # Warmup for stability\n","        lr_scheduler_type=\"cosine\",  # Cosine decay for smooth convergence\n","        dataloader_num_workers=workers,\n","        dataloader_pin_memory=True,\n","        dataloader_prefetch_factor=2,  # Prefetch for efficiency\n","        group_by_length=True,  # Group similar lengths for efficiency\n","        max_steps=-1,  # No limit - early stopping will handle this\n","    )\n","\n","    print(f\"âœ… Training config: Batch size={batch_size}, Gradient accum={gradient_accum}, Workers={workers}\")\n","\n","    def formatting_func(example):\n","        return \"\\n\".join([\n","            f\"### {msg['role'].capitalize()}: {msg['content']} ###\"\n","            for msg in example[\"messages\"]\n","        ])\n","\n","    # Create callback to monitor loss and stop if in optimal range\n","    early_stop_callback = EarlyStoppingOnLossCallback(\n","        target_loss_threshold=0.1,  # Stop when loss drops below 0.1\n","        patience=50,                # Wait 50 steps below threshold before stopping\n","        auto_stop=True              # Automatically stop training\n","    )\n","\n","    print(\"Creating SFTTrainer with EarlyStoppingOnLoss callback...\")\n","    print(f\"ðŸ“Š Will monitor loss and save checkpoint when it drops below 0.1\")\n","    print(f\"ðŸ›‘ Auto-stop enabled: Training will stop after 50 steps below threshold\")\n","\n","    return SFTTrainer(\n","        model=model,\n","        processing_class=tokenizer,\n","        train_dataset=dataset[\"train\"],\n","        eval_dataset=dataset[\"validation\"] if training_args.eval_strategy != \"no\" else None,\n","        args=training_args,\n","        formatting_func=formatting_func,\n","        peft_config=None,\n","        callbacks=[early_stop_callback],\n","    )\n","\n","def main():\n","    torch.cuda.empty_cache()  # Clear GPU memory\n","    print(\"Loading and preparing dataset...\")\n","    dataset = load_and_format_dataset(\"bio_mistral_qa_combined.csv\", max_samples=None)  # Use full dataset\n","    print(f\"Dataset loaded: {dataset}\")\n","\n","    print(\"Loading tokenizer...\")\n","    tokenizer = AutoTokenizer.from_pretrained(\"medalpaca/medalpaca-7b\", use_fast=False)\n","    if tokenizer.pad_token is None:\n","        tokenizer.pad_token = tokenizer.eos_token\n","\n","    print(\"Preprocessing and tokenizing dataset...\")\n","    dataset = preprocess_and_save_dataset(dataset, tokenizer)\n","    print(f\"Preprocessed dataset: {dataset}\")\n","\n","    # Clear tokenizer from memory before loading full model\n","    del tokenizer\n","    torch.cuda.empty_cache()\n","\n","    print(\"Configuring QLoRA model...\")\n","    model, tokenizer = configure_qlora_model()  # Load model only once\n","    print(\"QLoRA model configured successfully!\")\n","\n","    if not isinstance(model, (PeftModel, PeftModelForCausalLM)):\n","        raise ValueError(\"Model is not properly wrapped as a PEFT model!\")\n","\n","    print(\"Setting up trainer...\")\n","    trainer = setup_trainer(model, tokenizer, dataset)\n","    print(\"Trainer configured successfully!\")\n","\n","    print(\"Starting training...\")\n","    trainer.train()\n","\n","    trainer.save_model()\n","    print(f\"Model trained and saved to {trainer.args.output_dir}\")\n","\n","    return model, tokenizer, trainer\n","\n","# Run training\n","model, tokenizer, trainer = main()"]},{"cell_type":"markdown","id":"b621d63f-90a4-48da-b6ea-764b5405bfbf","metadata":{"id":"b621d63f-90a4-48da-b6ea-764b5405bfbf"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"id":"83c5e156-76e3-44c5-873b-9ec6cfd95767","metadata":{"id":"83c5e156-76e3-44c5-873b-9ec6cfd95767","outputId":"08f6a080-6b52-4c3e-ed6d-8ada0e2736ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.57.1)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (4.3.0)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.9.0)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.3.3)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (2.2.6)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.7.2)\n","Requirement already satisfied: rouge-score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.9.2)\n","Collecting scispacy\n","  Downloading scispacy-0.6.2-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.36.0)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2025.10.23)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.5)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=21.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (22.0.0)\n","Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.4.0)\n","Requirement already satisfied: httpx<1.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.28.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2023.12.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.15.0)\n","Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.10/site-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.10/site-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.10/site-packages (from torch) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.10/site-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.10/site-packages (from torch) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.1.3)\n","Requirement already satisfied: triton==3.5.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2025.2)\n","Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (2.3.1)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n","Requirement already satisfied: spacy<3.9.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from scispacy) (3.8.7)\n","Collecting conllu (from scispacy)\n","  Downloading conllu-6.0.0-py3-none-any.whl.metadata (21 kB)\n","Collecting numpy\n","  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nmslib-metabrainz==2.1.3 (from scispacy)\n","  Downloading nmslib_metabrainz-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (956 bytes)\n","Collecting pysbd (from scispacy)\n","  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n","Collecting pybind11>=2.2.3 (from nmslib-metabrainz==2.1.3->scispacy)\n","  Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from nmslib-metabrainz==2.1.3->scispacy) (5.9.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (4.1.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (2023.11.17)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n","Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (3.4)\n","Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (1.0.13)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (3.0.10)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (8.3.6)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (0.20.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (2.12.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (68.2.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.9.0,>=3.7.0->scispacy) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (23.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.9.0,>=3.7.0->scispacy) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.9.0,>=3.7.0->scispacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.9.0,>=3.7.0->scispacy) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.9.0,>=3.7.0->scispacy) (0.4.2)\n","Requirement already satisfied: blis<1.4.0,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9.0,>=3.7.0->scispacy) (1.3.0)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9.0,>=3.7.0->scispacy) (0.1.5)\n","INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n","Collecting thinc<8.4.0,>=8.3.4 (from spacy<3.9.0,>=3.7.0->scispacy)\n","  Downloading thinc-8.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n","Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy<3.9.0,>=3.7.0->scispacy)\n","  Downloading blis-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n","Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.9.0,>=3.7.0->scispacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.9.0,>=3.7.0->scispacy) (14.2.0)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9.0,>=3.7.0->scispacy) (0.23.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9.0,>=3.7.0->scispacy) (7.4.1)\n","Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.0.4)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.9.0,>=3.7.0->scispacy) (1.3.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.9.0,>=3.7.0->scispacy) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.9.0,>=3.7.0->scispacy) (2.15.1)\n","Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.9.0,>=3.7.0->scispacy) (2.0.0)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.9.0,>=3.7.0->scispacy) (0.1.2)\n","Downloading scispacy-0.6.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nmslib_metabrainz-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading conllu-6.0.0-py3-none-any.whl (16 kB)\n","Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pybind11-3.0.1-py3-none-any.whl (293 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading thinc-8.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading blis-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: pysbd, pybind11, numpy, conllu, nmslib-metabrainz, blis, thinc, scispacy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.2.6\n","    Uninstalling numpy-2.2.6:\n","      Successfully uninstalled numpy-2.2.6\n","  Attempting uninstall: blis\n","    Found existing installation: blis 1.3.0\n","    Uninstalling blis-1.3.0:\n","      Successfully uninstalled blis-1.3.0\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.3.6\n","    Uninstalling thinc-8.3.6:\n","      Successfully uninstalled thinc-8.3.6\n","Successfully installed blis-1.2.1 conllu-6.0.0 nmslib-metabrainz-2.1.3 numpy-1.26.4 pybind11-3.0.1 pysbd-0.3.4 scispacy-0.6.2 thinc-8.3.4\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (5.1.2)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.57.1)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.9.0)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.7.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.36.0)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.0.1)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.15.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.12.2)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n","Requirement already satisfied: triton==3.5.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.23)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n","Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2023.11.17)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install transformers datasets torch pandas numpy scikit-learn rouge-score nltk scispacy\n","\n","!pip install sentence-transformers"]},{"cell_type":"code","execution_count":null,"id":"26ed50e7-c8e0-4aeb-81c3-9f681b0e595e","metadata":{"id":"26ed50e7-c8e0-4aeb-81c3-9f681b0e595e","outputId":"14bc8ae9-37d5-4674-8419-1e402c40e47d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\n","  Downloading https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz (120.2 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m120.2/120.2 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting spacy<3.5.0,>=3.4.1 (from en-ner-bc5cdr-md==0.5.1)\n","  Downloading spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (1.0.13)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (3.0.10)\n","Collecting thinc<8.2.0,>=8.1.0 (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1)\n","  Downloading thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n","Collecting wasabi<1.1.0,>=0.9.1 (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1)\n","  Downloading wasabi-0.10.1-py3-none-any.whl.metadata (28 kB)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2.0.10)\n","Collecting typer<0.8.0,>=0.3.0 (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1)\n","  Downloading typer-0.7.0-py3-none-any.whl.metadata (17 kB)\n","Collecting pathy>=0.3.5 (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1)\n","  Downloading pathy-0.11.0-py3-none-any.whl.metadata (16 kB)\n","Collecting smart-open<7.0.0,>=5.2.1 (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1)\n","  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (4.67.1)\n","Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (1.26.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2.32.5)\n","Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1)\n","  Downloading pydantic-1.10.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (154 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (3.1.2)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (68.2.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (23.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (3.5.0)\n","Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (1.3.0)\n","Collecting pathlib-abc==0.1.1 (from pathy>=0.3.5->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1)\n","  Downloading pathlib_abc-0.1.1-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (4.15.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2023.11.17)\n","Collecting blis<0.8.0,>=0.7.8 (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1)\n","  Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (0.1.5)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (2.1.1)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.1->en-ner-bc5cdr-md==0.5.1) (1.3.1)\n","Downloading spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading pathy-0.11.0-py3-none-any.whl (47 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pathlib_abc-0.1.1-py3-none-any.whl (23 kB)\n","Downloading pydantic-1.10.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m919.6/919.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading typer-0.7.0-py3-none-any.whl (38 kB)\n","Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n","Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: en-ner-bc5cdr-md\n","  Building wheel for en-ner-bc5cdr-md (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for en-ner-bc5cdr-md: filename=en_ner_bc5cdr_md-0.5.1-py3-none-any.whl size=120217632 sha256=63f302064deb77ef7418be5930a23cddae38135f58dd0b3fb8a24980cd8239a1\n","  Stored in directory: /root/.cache/pip/wheels/89/bf/71/af9266a822964b06d994e4cd80dd9300018b20027b8ae5ae14\n","Successfully built en-ner-bc5cdr-md\n","Installing collected packages: wasabi, typer, smart-open, pydantic, pathlib-abc, blis, pathy, thinc, spacy, en-ner-bc5cdr-md\n","  Attempting uninstall: wasabi\n","    Found existing installation: wasabi 1.1.3\n","    Uninstalling wasabi-1.1.3:\n","      Successfully uninstalled wasabi-1.1.3\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.20.0\n","    Uninstalling typer-0.20.0:\n","      Successfully uninstalled typer-0.20.0\n","  Attempting uninstall: smart-open\n","    Found existing installation: smart_open 7.4.1\n","    Uninstalling smart_open-7.4.1:\n","      Successfully uninstalled smart_open-7.4.1\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 2.12.3\n","    Uninstalling pydantic-2.12.3:\n","      Successfully uninstalled pydantic-2.12.3\n","  Attempting uninstall: blis\n","    Found existing installation: blis 1.2.1\n","    Uninstalling blis-1.2.1:\n","      Successfully uninstalled blis-1.2.1\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.3.4\n","    Uninstalling thinc-8.3.4:\n","      Successfully uninstalled thinc-8.3.4\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.8.7\n","    Uninstalling spacy-3.8.7:\n","      Successfully uninstalled spacy-3.8.7\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","scispacy 0.6.2 requires spacy<3.9.0,>=3.7.0, but you have spacy 3.4.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed blis-0.7.11 en-ner-bc5cdr-md-0.5.1 pathlib-abc-0.1.1 pathy-0.11.0 pydantic-1.10.24 smart-open-6.4.0 spacy-3.4.4 thinc-8.1.12 typer-0.7.0 wasabi-0.10.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz"]},{"cell_type":"code","execution_count":null,"id":"468e5c81-6c51-477e-97b2-1d1eacf15856","metadata":{"id":"468e5c81-6c51-477e-97b2-1d1eacf15856","outputId":"03c1297f-a7c4-46dc-bd5a-66b96bf168f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: numpy 1.26.4\n","Uninstalling numpy-1.26.4:\n","  Successfully uninstalled numpy-1.26.4\n","Found existing installation: thinc 8.1.12\n","Uninstalling thinc-8.1.12:\n","  Successfully uninstalled thinc-8.1.12\n","Found existing installation: spacy 3.4.4\n","Uninstalling spacy-3.4.4:\n","  Successfully uninstalled spacy-3.4.4\n","Found existing installation: scispacy 0.6.2\n","Uninstalling scispacy-0.6.2:\n","  Successfully uninstalled scispacy-0.6.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting numpy==1.26.4\n","  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","Installing collected packages: numpy\n","Successfully installed numpy-1.26.4\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting spacy==3.7.2\n","  Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (1.0.13)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (3.0.10)\n","Collecting thinc<8.3.0,>=8.1.8 (from spacy==3.7.2)\n","  Downloading thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (0.10.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (2.0.10)\n","Collecting weasel<0.4.0,>=0.1.0 (from spacy==3.7.2)\n","  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (0.7.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (2.32.5)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (1.10.24)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (3.1.2)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (68.2.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (23.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy==3.7.2) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.7.2) (1.3.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2) (4.15.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2) (2023.11.17)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2) (0.1.5)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy==3.7.2) (8.1.7)\n","Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy==3.7.2)\n","  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy==3.7.2) (2.1.1)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.7.2) (1.3.1)\n","Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading weasel-0.3.4-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: cloudpathlib, weasel, thinc, spacy\n","  Attempting uninstall: cloudpathlib\n","    Found existing installation: cloudpathlib 0.23.0\n","    Uninstalling cloudpathlib-0.23.0:\n","      Successfully uninstalled cloudpathlib-0.23.0\n","  Attempting uninstall: weasel\n","    Found existing installation: weasel 0.4.1\n","    Uninstalling weasel-0.4.1:\n","      Successfully uninstalled weasel-0.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","en-ner-bc5cdr-md 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.7.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cloudpathlib-0.16.0 spacy-3.7.2 thinc-8.2.5 weasel-0.3.4\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting scispacy==0.5.1\n","  Downloading scispacy-0.5.1-py3-none-any.whl.metadata (15 kB)\n","Collecting spacy<3.5.0,>=3.4.0 (from scispacy==0.5.1)\n","  Using cached spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scispacy==0.5.1) (2.32.5)\n","Requirement already satisfied: conllu in /opt/conda/lib/python3.10/site-packages (from scispacy==0.5.1) (6.0.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from scispacy==0.5.1) (1.26.4)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from scispacy==0.5.1) (1.5.2)\n","Collecting nmslib>=1.7.3.6 (from scispacy==0.5.1)\n","  Downloading nmslib-2.1.2.tar.gz (197 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m197.2/197.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from scispacy==0.5.1) (1.7.2)\n","Requirement already satisfied: pysbd in /opt/conda/lib/python3.10/site-packages (from scispacy==0.5.1) (0.3.4)\n","Requirement already satisfied: pybind11>=2.2.3 in /opt/conda/lib/python3.10/site-packages (from nmslib>=1.7.3.6->scispacy==0.5.1) (3.0.1)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from nmslib>=1.7.3.6->scispacy==0.5.1) (1.15.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->scispacy==0.5.1) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->scispacy==0.5.1) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->scispacy==0.5.1) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->scispacy==0.5.1) (2023.11.17)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.3->scispacy==0.5.1) (3.6.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (1.0.13)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (3.0.10)\n","Collecting thinc<8.2.0,>=8.1.0 (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1)\n","  Using cached thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (0.10.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (2.0.10)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (0.7.0)\n","Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (0.11.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (4.67.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (1.10.24)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (3.1.2)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (68.2.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (23.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (3.5.0)\n","Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (1.3.0)\n","Requirement already satisfied: pathlib-abc==0.1.1 in /opt/conda/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (0.1.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (4.15.0)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (0.1.5)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (2.1.1)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.0->scispacy==0.5.1) (1.3.1)\n","Downloading scispacy-0.5.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n","Using cached thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n","Building wheels for collected packages: nmslib\n","  Building wheel for nmslib (pyproject.toml) ... \u001b[?25lerror\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31mÃ—\u001b[0m \u001b[32mBuilding wheel for nmslib \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n","  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31mâ•°â”€>\u001b[0m \u001b[31m[58 lines of output]\u001b[0m\n","  \u001b[31m   \u001b[0m Dependence list: ['pybind11>=2.2.3', 'scipy', \"numpy>=1.10.0 ; python_version>='3.5'\"]\n","  \u001b[31m   \u001b[0m running bdist_wheel\n","  \u001b[31m   \u001b[0m running build\n","  \u001b[31m   \u001b[0m running build_ext\n","  \u001b[31m   \u001b[0m creating tmp\n","  \u001b[31m   \u001b[0m g++ -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/include/python3.10 -c /tmp/tmppps6ux5j.cpp -o tmp/tmppps6ux5j.o -std=c++14\n","  \u001b[31m   \u001b[0m g++ -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/include/python3.10 -c /tmp/tmpm0t1qwcq.cpp -o tmp/tmpm0t1qwcq.o -std=c++11\n","  \u001b[31m   \u001b[0m Traceback (most recent call last):\n","  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n","  \u001b[31m   \u001b[0m     main()\n","  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n","  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n","  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 251, in build_wheel\n","  \u001b[31m   \u001b[0m     return _build_backend().build_wheel(wheel_directory, config_settings,\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 435, in build_wheel\n","  \u001b[31m   \u001b[0m     return _build(['bdist_wheel', '--dist-info-dir', str(metadata_directory)])\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 423, in _build\n","  \u001b[31m   \u001b[0m     return self._build_with_temp_dir(\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 404, in _build_with_temp_dir\n","  \u001b[31m   \u001b[0m     self.run_setup()\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 317, in run_setup\n","  \u001b[31m   \u001b[0m     exec(code, locals())\n","  \u001b[31m   \u001b[0m   File \"<string>\", line 183, in <module>\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/__init__.py\", line 115, in setup\n","  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 186, in setup\n","  \u001b[31m   \u001b[0m     return run_commands(dist)\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 202, in run_commands\n","  \u001b[31m   \u001b[0m     dist.run_commands()\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 1002, in run_commands\n","  \u001b[31m   \u001b[0m     self.run_command(cmd)\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/dist.py\", line 1102, in run_command\n","  \u001b[31m   \u001b[0m     super().run_command(command)\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 1021, in run_command\n","  \u001b[31m   \u001b[0m     cmd_obj.run()\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/command/bdist_wheel.py\", line 370, in run\n","  \u001b[31m   \u001b[0m     self.run_command(\"build\")\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 357, in run_command\n","  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/dist.py\", line 1102, in run_command\n","  \u001b[31m   \u001b[0m     super().run_command(command)\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 1021, in run_command\n","  \u001b[31m   \u001b[0m     cmd_obj.run()\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/_distutils/command/build.py\", line 135, in run\n","  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 357, in run_command\n","  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/dist.py\", line 1102, in run_command\n","  \u001b[31m   \u001b[0m     super().run_command(command)\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 1021, in run_command\n","  \u001b[31m   \u001b[0m     cmd_obj.run()\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/command/build_ext.py\", line 96, in run\n","  \u001b[31m   \u001b[0m     _build_ext.run(self)\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-dzcp02va/overlay/lib/python3.10/site-packages/setuptools/_distutils/command/build_ext.py\", line 368, in run\n","  \u001b[31m   \u001b[0m     self.build_extensions()\n","  \u001b[31m   \u001b[0m   File \"<string>\", line 158, in build_extensions\n","  \u001b[31m   \u001b[0m   File \"<string>\", line 108, in cpp_flag\n","  \u001b[31m   \u001b[0m RuntimeError: Unsupported compiler -- at least C++11 support is needed!\n","  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","\u001b[31m  ERROR: Failed building wheel for nmslib\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25hFailed to build nmslib\n","\u001b[31mERROR: Could not build wheels for nmslib, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip uninstall -y numpy thinc spacy scispacy\n","!pip install numpy==1.26.4\n","!pip install spacy==3.7.2\n","!pip install scispacy==0.5.1\n"]},{"cell_type":"code","execution_count":null,"id":"8f275f9e-89a8-4f2b-af25-db988a6405a8","metadata":{"id":"8f275f9e-89a8-4f2b-af25-db988a6405a8","outputId":"719b19ca-1fe9-431e-a015-e3295bb6d1ff"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download(\"punkt\")"]},{"cell_type":"code","execution_count":null,"id":"b5434a68-1a86-410a-a912-5d1dd35939fa","metadata":{"id":"b5434a68-1a86-410a-a912-5d1dd35939fa","outputId":"76596917-22fe-4a94-d180-3dfdeaf2aa7f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.57.1)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.9.0)\n","Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (5.1.2)\n","Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.2)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.9.2)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.3.3)\n","Requirement already satisfied: rouge-score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2025.10.23)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.5)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.67.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.15.0)\n","Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.10/site-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec>=0.8.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2023.12.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.10/site-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.10/site-packages (from torch) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.10/site-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.10/site-packages (from torch) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.1.3)\n","Requirement already satisfied: triton==3.5.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.5.0)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.7.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.0.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.13)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.10)\n","Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.10.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.7.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.4.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.10.24)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (68.2.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.5.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.5.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2025.2)\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (2.3.1)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.5)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install transformers torch sentence-transformers spacy nltk pandas rouge-score"]},{"cell_type":"code","execution_count":null,"id":"0f8ce288-6eea-46ad-be54-3ed55a683cb1","metadata":{"id":"0f8ce288-6eea-46ad-be54-3ed55a683cb1","outputId":"dfa41efa-5a8a-4c2d-a5c5-5c994565abad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.11.0)\n","Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.48.1)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.57.1)\n","Requirement already satisfied: bert-score in /opt/conda/lib/python3.10/site-packages (0.3.13)\n","Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.17.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.1)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.9.0)\n","Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.36.0)\n","Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.6.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2025.10.23)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.5)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.3.3)\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.10.7)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2023.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n","Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n","Requirement already satisfied: triton==3.5.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (10.0.1)\n","Requirement already satisfied: pyparsing>=3 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (3.2.5)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install accelerate bitsandbytes transformers bert-score peft"]},{"cell_type":"code","execution_count":null,"id":"ee42e323-f46f-42d1-80b7-e8e017efa2b2","metadata":{"id":"ee42e323-f46f-42d1-80b7-e8e017efa2b2","outputId":"e45f0c28-3f83-4a0d-cb43-fab3f0a6399b"},"outputs":[{"ename":"ValueError","evalue":"numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/spacy/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[1;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/spacy/errors.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/spacy/compat.py:39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatalogue\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _importlib_metadata \u001b[38;5;28;01mas\u001b[39;00m importlib_metadata  \u001b[38;5;66;03m# type: ignore[no-redef]    # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     41\u001b[0m pickle \u001b[38;5;241m=\u001b[39m pickle\n\u001b[1;32m     42\u001b[0m copy_reg \u001b[38;5;241m=\u001b[39m copy_reg\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/api.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     CupyOps,\n\u001b[1;32m      3\u001b[0m     MPSOps,\n\u001b[1;32m      4\u001b[0m     NumpyOps,\n\u001b[1;32m      5\u001b[0m     Ops,\n\u001b[1;32m      6\u001b[0m     get_current_ops,\n\u001b[1;32m      7\u001b[0m     get_ops,\n\u001b[1;32m      8\u001b[0m     set_current_ops,\n\u001b[1;32m      9\u001b[0m     set_gpu_allocator,\n\u001b[1;32m     10\u001b[0m     use_ops,\n\u001b[1;32m     11\u001b[0m     use_pytorch_for_gpu_memory,\n\u001b[1;32m     12\u001b[0m     use_tensorflow_for_gpu_memory,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enable_mxnet, enable_tensorflow, has_cupy\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, ConfigValidationError, registry\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/backends/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cupy_allocators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cupy_pytorch_allocator, cupy_tensorflow_allocator\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_server\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParamServer\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcupy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CupyOps\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MPSOps\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumpyOps\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/backends/cupy_ops.py:16\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     is_cupy_array,\n\u001b[1;32m      8\u001b[0m     is_mxnet_gpu_array,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     torch2xp,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _custom_kernels\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumpyOps\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@registry\u001b[39m\u001b[38;5;241m.\u001b[39mops(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCupyOps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCupyOps\u001b[39;00m(Ops):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/thinc/backends/numpy_ops.pyx:1\u001b[0m, in \u001b[0;36minit thinc.backends.numpy_ops\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"]}],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","from peft import PeftModel\n","import logging\n","import re\n","import spacy\n","from nltk.tokenize import word_tokenize\n","import nltk\n","from rouge_score import rouge_scorer\n","from bert_score import score as bert_score\n","from sentence_transformers import SentenceTransformer, util\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","import os\n","\n","# Suppress transformers warnings\n","logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n","\n","# Download NLTK data\n","nltk.download(\"punkt\")\n","nltk.download(\"punkt_tab\")\n","nltk.download(\"wordnet\")"]},{"cell_type":"code","execution_count":null,"id":"ec51e00c-1124-4433-9517-af92c1deda26","metadata":{"id":"ec51e00c-1124-4433-9517-af92c1deda26"},"outputs":[],"source":["# Load spaCy and SentenceTransformer models\n","def load_spacy_model():\n","    \"\"\"Load spaCy medical NER model.\"\"\"\n","    try:\n","        return spacy.load(\"en_ner_bc5cdr_md\")\n","    except Exception as e:\n","        print(f\"Error loading spaCy model: {e}\")\n","        return None\n","\n","def load_sentence_transformer():\n","    \"\"\"Load SentenceTransformer for FCS.\"\"\"\n","    try:\n","        return SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    except Exception as e:\n","        print(f\"Error loading SentenceTransformer: {e}\")\n","        return None\n","\n","nlp = load_spacy_model()\n","embedder = load_sentence_transformer()"]},{"cell_type":"code","execution_count":null,"id":"0d3b8b62-8fae-4495-9eb1-10b0d709c71f","metadata":{"id":"0d3b8b62-8fae-4495-9eb1-10b0d709c71f"},"outputs":[],"source":["# Load fine-tuned model and tokenizer\n","def load_fine_tuned_model(model_name=\"medalpaca/medalpaca\", checkpoint_dir=\"medalpaca_finetuned\"):\n","    \"\"\"Load the fine-tuned QLoRA model and tokenizer.\"\"\"\n","    try:\n","        tokenizer = AutoTokenizer.from_pretrained(model_name)\n","        if tokenizer.pad_token is None:\n","            tokenizer.pad_token = tokenizer.eos_token\n","\n","        bnb_config = BitsAndBytesConfig(\n","            load_in_4bit=True,\n","            bnb_4bit_quant_type=\"nf4\",\n","            bnb_4bit_compute_dtype=torch.float16,\n","            bnb_4bit_use_double_quant=False,\n","            llm_int8_enable_fp32_cpu_offload=True,\n","            llm_int8_skip_modules=[\"lm_head\"]\n","        )\n","\n","        base_model = AutoModelForCausalLM.from_pretrained(\n","            model_name,\n","            quantization_config=bnb_config,\n","            device_map=\"auto\",\n","            dtype=torch.float16,\n","            trust_remote_code=True,\n","            offload_folder=\"offload\",\n","            low_cpu_mem_usage=True,\n","            offload_state_dict=True\n","        )\n","        base_model.config.pad_token_id = tokenizer.eos_token_id\n","\n","        if os.path.exists(checkpoint_dir):\n","            if os.path.exists(os.path.join(checkpoint_dir, \"adapter_model.bin\")):\n","                print(f\"Loading fine-tuned model from {checkpoint_dir}\")\n","                model = PeftModel.from_pretrained(base_model, checkpoint_dir, is_trainable=False)\n","            else:\n","                checkpoints = [d for d in os.listdir(checkpoint_dir) if d.startswith(\"checkpoint-\")]\n","                if checkpoints:\n","                    latest_checkpoint = max(checkpoints, key=lambda x: int(x.split(\"-\")[1]))\n","                    checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n","                    print(f\"Loading fine-tuned model from checkpoint: {checkpoint_path}\")\n","                    model = PeftModel.from_pretrained(base_model, checkpoint_path, is_trainable=False)\n","                else:\n","                    raise ValueError(f\"No checkpoints or final model found in {checkpoint_dir}\")\n","        else:\n","            raise ValueError(f\"Checkpoint directory {checkpoint_dir} does not exist\")\n","\n","        return model, tokenizer\n","    except Exception as e:\n","        print(f\"Error loading fine-tuned model: {e}\")\n","        return None, None\n","\n","model, tokenizer = load_fine_tuned_model()\n","if model is None or tokenizer is None:\n","    raise ValueError(\"Failed to load fine-tuned model or tokenizer\")"]},{"cell_type":"code","execution_count":null,"id":"f9244103-6fa2-4386-a4d2-4fd87e5b3199","metadata":{"id":"f9244103-6fa2-4386-a4d2-4fd87e5b3199"},"outputs":[],"source":["# âœ… Manually define 5 QA pairs (3 curated + 2 additional realistic)\n","questions = [\n","    \"Are there any further procedures planned for the patient?\",\n","    \"Does the patient require long term monitoring?\",\n","    \"What precautions does the patient need to take post-discharge?\",\n","    \"What medications is the patient currently taking?\",\n","    \"What is the patient's primary diagnosis?\"\n","]\n","\n","inputs = [\n","    \"Gender: F\\nChief Complaint: Abdominal distention, nausea, and vomiting\\nHistory: Cirrhosis, multiple paracenteses for ascites\\nPlan: Schedule regular paracentesis every 2 weeks\",\n","    \"Gender: F\\nChief Complaint: Abdominal distention, nausea, and vomiting\\nPlan: Monitor weight and abdominal girth daily; assess for signs of fluid overload\",\n","    \"Gender: M\\nChief Complaint: Abd pain, Hypotension\\nDischarge Plan: Follow low sodium diet, take prescribed meds, and avoid strenuous activity\",\n","    \"Gender: F\\nCurrent Medications: Lisinopril 10mg daily, Furosemide 40mg daily\\nAllergies: None known\\nAssessment: Hypertension, fluid retention\",\n","    \"Gender: M\\nChief Complaint: Fever, Cough\\nFindings: CXR shows consolidation in the right lower lobe\\nAssessment: Community-acquired pneumonia\"\n","]\n","\n","references = [\n","    \"Yes, the patient requires regular paracentesis due to fluid accumulation.\",\n","    \"Yes, the patient requires close monitoring for fluid accumulation and symptoms.\",\n","    \"Follow up with the doctor or nurse practitioner. Avoid heavy lifting and follow dietary guidelines.\",\n","    \"The patient is currently taking Lisinopril and Furosemide.\",\n","    \"The patient's primary diagnosis is community-acquired pneumonia.\"\n","]"]},{"cell_type":"code","execution_count":null,"id":"05b3c806-2e03-4256-82e0-fbbc2a88f1da","metadata":{"id":"05b3c806-2e03-4256-82e0-fbbc2a88f1da"},"outputs":[],"source":["# Prompt and validation functions\n","def create_prompt(question, context):\n","    \"\"\"Create a prompt for the model.\"\"\"\n","    return f\"\"\"You are a clinical assistant. Provide concise, factual answers based ONLY on the available information.\n","\n","Question: {question}\n","Available Context: {context if context.strip() else \"No specific clinical data provided\"}\n","\n","Answer (just the factual medical response, no references to tables/figures):\"\"\"\n","\n","def validate_answer(answer):\n","    \"\"\"Validate generated answer to exclude invalid phrases.\"\"\"\n","    invalid_phrases = [\"Table\", \"Figure\", \"as shown in\", \"refer to\"]\n","    if any(phrase.lower() in answer.lower() for phrase in invalid_phrases):\n","        return \"Unable to generate proper response from available data\"\n","    return answer.strip()\n","\n","# Dataset class for generation\n","class QADataset(Dataset):\n","    \"\"\"Dataset class for question answering.\"\"\"\n","    def __init__(self, questions, inputs, references, tokenizer, max_length=256):\n","        self.questions = questions\n","        self.inputs = inputs\n","        self.references = references\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, idx):\n","        question = self.questions[idx]\n","        input_text = self.inputs[idx]\n","        prompt = create_prompt(question, input_text)\n","        encoding = self.tokenizer(\n","            prompt,\n","            max_length=self.max_length,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","        return {\n","            'input_ids': encoding['input_ids'].squeeze(0),\n","            'attention_mask': encoding['attention_mask'].squeeze(0),\n","            'prompt_length': encoding['input_ids'].shape[1],\n","            'question': question,\n","            'input_text': input_text,\n","            'reference': self.references[idx]\n","        }\n","\n","# Generate responses\n","def generate_responses(model, tokenizer, questions, inputs, references):\n","    \"\"\"Generate responses for the dataset.\"\"\"\n","    bad_words = [\"Table\", \"Figure\"]\n","    bad_words_ids = [tokenizer.encode(word, add_special_tokens=False) for word in bad_words if tokenizer.encode(word, add_special_tokens=False)]\n","\n","    generation_kwargs = {\n","        'max_new_tokens': 150,\n","        'do_sample': True,\n","        'temperature': 0.3,\n","        'repetition_penalty': 1.5,\n","        'no_repeat_ngram_size': 4,\n","        'bad_words_ids': bad_words_ids if bad_words_ids else None,\n","        'eos_token_id': tokenizer.eos_token_id,\n","        'pad_token_id': tokenizer.pad_token_id\n","    }\n","\n","    qa_dataset = QADataset(questions, inputs, references, tokenizer)\n","    dataloader = DataLoader(qa_dataset, batch_size=1, shuffle=False)\n","    generated_outputs = []\n","    sample_number = 0\n","\n","    try:\n","        for batch in dataloader:\n","            sample_number += 1\n","            input_ids = batch['input_ids'].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","            attention_mask = batch['attention_mask'].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","            question = batch['question'][0]\n","            input_text = batch['input_text'][0]\n","            reference = batch['reference'][0]\n","            prompt_length = batch['prompt_length'][0]\n","\n","            print(f\"\\n=== Sample {sample_number} ===\")\n","            print(f\"Instruction: {question}\")\n","            print(f\"Input: {input_text}\")\n","\n","            with torch.amp.autocast(device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\", dtype=torch.float16):\n","                outputs = model.generate(\n","                    input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    **generation_kwargs\n","                )\n","\n","            if outputs.shape[1] > prompt_length:\n","                new_tokens = outputs[0, prompt_length:]\n","            else:\n","                print(f\"Warning: No new tokens generated for sample {sample_number}\")\n","                new_tokens = outputs[0]\n","\n","            generated_answer = tokenizer.decode(new_tokens, skip_special_tokens=True)\n","            generated_answer = validate_answer(generated_answer)\n","\n","            print(f\"Generated Answer: {generated_answer}\")\n","            print(f\"Ground Truth Answer: {reference}\")\n","\n","            generated_outputs.append(generated_answer)\n","\n","        print(f\"\\nProcessed {sample_number} samples\")\n","        return generated_outputs\n","\n","    except Exception as e:\n","        print(f\"Error during generation: {str(e)}\")\n","        print(f\"Stopped at sample {sample_number}\")\n","        print(f\"Problematic sample details: {question}, {input_text}\")\n","        return generated_outputs\n","\n","generated_outputs = generate_responses(model, tokenizer, questions, inputs, references)"]},{"cell_type":"code","execution_count":null,"id":"6418b7e4-92ea-43f0-ba0c-d819ba01c8cb","metadata":{"id":"6418b7e4-92ea-43f0-ba0c-d819ba01c8cb"},"outputs":[],"source":["import os\n","os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY_FROM_ENV\"  # replace with your actual key"]},{"cell_type":"code","execution_count":null,"id":"2ac1d9f4-79ee-41bd-b827-4e4fe7af997a","metadata":{"id":"2ac1d9f4-79ee-41bd-b827-4e4fe7af997a"},"outputs":[],"source":["import re\n","import numpy as np\n","import openai\n","from nltk.tokenize import word_tokenize\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from rouge_score import rouge_scorer\n","from bert_score import score as bert_score\n","from sentence_transformers import SentenceTransformer, util\n","from nltk.translate.meteor_score import meteor_score\n","import torch\n","from torch import cuda\n","from openai import OpenAI\n","import os\n","\n","# Set your OpenAI API key\n","openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n","\n","def preprocess_text(text):\n","    text = text.lower()\n","    text = re.sub(r'[^\\w\\s]', ' ', text)\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    tokens = word_tokenize(text)\n","    return ' '.join(tokens)\n","\n","def compute_bleu_score(generated, reference):\n","    gen_tokens = word_tokenize(generated)\n","    ref_tokens = word_tokenize(reference)\n","    smoothie = SmoothingFunction().method4\n","    return sentence_bleu([ref_tokens], gen_tokens, smoothing_function=smoothie)\n","\n","def compute_hybrid_score(bert_f1, bleu, bert_weight=0.7):\n","    return bert_weight * bert_f1 + (1 - bert_weight) * bleu\n","\n","client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n","\n","def call_gpt4o(prompt, max_tokens=10):\n","    try:\n","        response = client.chat.completions.create(\n","            model=\"gpt-4o\",\n","            messages=[{\"role\": \"user\", \"content\": prompt}],\n","            temperature=0.2,\n","            max_tokens=max_tokens,\n","        )\n","        reply = response.choices[0].message.content.strip()\n","        match = re.search(r\"\\d*\\.\\d+|\\d+\", reply)\n","        return float(match.group(0)) if match else 0.5\n","    except Exception as e:\n","        print(f\"GPT-4o error: {e}\")\n","        return 0.5\n","\n","def compute_llm_judge_score(generated, reference, question):\n","    prompt = (\n","        f\"You are an expert medical evaluator. Score the following generated answer from 0 to 1 \"\n","        f\"based on factual accuracy and clinical relevance to the reference.\\n\\n\"\n","        f\"Question: {question}\\n\"\n","        f\"Generated Answer: {generated}\\n\"\n","        f\"Reference Answer: {reference}\\n\\n\"\n","        f\"Just reply with a score (e.g., 0.73).\"\n","    )\n","    return call_gpt4o(prompt)\n","\n","def compute_geval_score(generated, reference, question):\n","    prompt = (\n","        f\"You are evaluating the clinical quality of a generated answer. Consider factual correctness, completeness, and clarity. \"\n","        f\"Score it from 0 to 1.\\n\\n\"\n","        f\"Question: {question}\\n\"\n","        f\"Generated Answer: {generated}\\n\"\n","        f\"Reference Answer: {reference}\\n\\n\"\n","        f\"Reply with a score (e.g., 0.82).\"\n","    )\n","    return call_gpt4o(prompt)\n","\n","def compute_metrics_per_query(generated_outputs, references, questions, nlp, embedder):\n","    rouge_scorer_obj = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n","\n","    # Metric containers\n","    bert_p_scores, bert_r_scores, bert_f1_scores = [], [], []\n","    rouge_l_scores, fcs_scores, bleu_scores, hybrid_scores = [], [], [], []\n","    entity_f1_scores, mcr_scores, meteor_scores = [], [], []\n","    llm_judge_scores, geval_scores = [], []\n","\n","    print(f\"\\n=== Per-Query Evaluation Metrics ===\")\n","\n","    for i, (gen, ref, question) in enumerate(zip(generated_outputs, references, questions), 1):\n","        gen_norm = preprocess_text(gen)\n","        ref_norm = preprocess_text(ref)\n","\n","        # BERTScore\n","        p, r, f1 = bert_score([gen_norm], [ref_norm], lang=\"en\", model_type=\"roberta-large\")\n","        bert_p = p.item()\n","        bert_r = r.item()\n","        bert_f1 = f1.item()\n","\n","        # ROUGE-L\n","        rouge_scores = rouge_scorer_obj.score(ref_norm, gen_norm)\n","        rouge_l = rouge_scores['rougeL'].fmeasure\n","\n","        # Entity F1\n","        gen_entities = set(ent.text.lower() for ent in nlp(gen).ents if ent.label_ in [\"DISEASE\", \"CHEMICAL\"])\n","        ref_entities = set(ent.text.lower() for ent in nlp(ref).ents if ent.label_ in [\"DISEASE\", \"CHEMICAL\"])\n","        if ref_entities:\n","            precision = len(gen_entities & ref_entities) / len(gen_entities) if gen_entities else 0\n","            recall = len(gen_entities & ref_entities) / len(ref_entities)\n","            entity_f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","        else:\n","            entity_f1 = 1.0 if not gen_entities else 0.0\n","\n","        # FCS (Fact Checking Score)\n","        gen_embedding = embedder.encode(gen, convert_to_tensor=True, device=\"cuda\" if cuda.is_available() else \"cpu\")\n","        ref_embedding = embedder.encode(ref, convert_to_tensor=True, device=\"cuda\" if cuda.is_available() else \"cpu\")\n","        fcs = util.cos_sim(gen_embedding, ref_embedding)[0][0].item()\n","\n","        # MCR (Medical Concept Recall)\n","        if ref_entities:\n","            matching_concepts = len(gen_entities.intersection(ref_entities))\n","            mcr = matching_concepts / len(ref_entities)\n","        else:\n","            mcr = 1.0 if not gen_entities else 0.0\n","\n","        # BLEU Score\n","        bleu = compute_bleu_score(gen_norm, ref_norm)\n","\n","        # Hybrid Score\n","        hybrid_score = compute_hybrid_score(bert_f1, bleu)\n","\n","        # METEOR Score\n","        meteor = meteor_score([word_tokenize(ref_norm)], word_tokenize(gen_norm))\n","\n","        # LLM Judge Score (GPT-4o)\n","        llm_judge_score = compute_llm_judge_score(gen, ref, question)\n","\n","        # GEval Score (GPT-4o)\n","        geval_score = compute_geval_score(gen, ref, question)\n","\n","        # Store scores\n","        bert_p_scores.append(bert_p)\n","        bert_r_scores.append(bert_r)\n","        bert_f1_scores.append(bert_f1)\n","        rouge_l_scores.append(rouge_l)\n","        entity_f1_scores.append(entity_f1)\n","        fcs_scores.append(fcs)\n","        mcr_scores.append(mcr)\n","        bleu_scores.append(bleu)\n","        hybrid_scores.append(hybrid_score)\n","        meteor_scores.append(meteor)\n","        llm_judge_scores.append(llm_judge_score)\n","        geval_scores.append(geval_score)\n","\n","        # Print\n","        print(f\"\\nSample {i}: {question}\")\n","        print(f\"Generated Answer: {gen}\")\n","        print(f\"Reference Answer: {ref}\")\n","        print(f\"BERTScore Precision: {bert_p:.4f}\")\n","        print(f\"BERTScore Recall: {bert_r:.4f}\")\n","        print(f\"BERTScore F1: {bert_f1:.4f}\")\n","        print(f\"ROUGE-L: {rouge_l:.4f}\")\n","        print(f\"FCS: {fcs:.4f}\")\n","        print(f\"BLEU: {bleu:.4f}\")\n","        print(f\"Hybrid BERT-BLEU: {hybrid_score:.4f}\")\n","        print(f\"METEOR: {meteor:.4f}\")\n","        print(f\"LLM Judge Score (GPT-4o): {llm_judge_score:.4f}\")\n","        print(f\"GEval Score (GPT-4o): {geval_score:.4f}\")\n","\n","    # Average metrics\n","    print(\"\\n=== Average Metrics Across All Queries ===\")\n","    print(f\"Average BERTScore Precision: {np.mean(bert_p_scores):.4f}\")\n","    print(f\"Average BERTScore Recall: {np.mean(bert_r_scores):.4f}\")\n","    print(f\"Average BERTScore F1: {np.mean(bert_f1_scores):.4f}\")\n","    print(f\"Average ROUGE-L: {np.mean(rouge_l_scores):.4f}\")\n","    print(f\"Average FCS: {np.mean(fcs_scores):.4f}\")\n","    print(f\"Average Entity F1: {np.mean(entity_f1_scores):.4f}\")\n","    print(f\"Average MCR: {np.mean(mcr_scores):.4f}\")\n","    print(f\"Average BLEU: {np.mean(bleu_scores):.4f}\")\n","    print(f\"Average Hybrid BERT-BLEU: {np.mean(hybrid_scores):.4f}\")\n","    print(f\"Average METEOR: {np.mean(meteor_scores):.4f}\")\n","    print(f\"Average LLM Judge Score (GPT-4o): {np.mean(llm_judge_scores):.4f}\")\n","    print(f\"Average GEval Score (GPT-4o): {np.mean(geval_scores):.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"c673bce0-a379-4721-b236-86240afb18f9","metadata":{"id":"c673bce0-a379-4721-b236-86240afb18f9","scrolled":true},"outputs":[],"source":["\n","# Evaluate generated outputs\n","if generated_outputs:\n","    compute_metrics_per_query(generated_outputs, references, questions, nlp, embedder)\n","else:\n","    print(\"No outputs generated due to error.\")\n","\n","# Clear GPU memory\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"id":"32528124-1be3-46fd-962c-9ee46661976a","metadata":{"id":"32528124-1be3-46fd-962c-9ee46661976a"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0086927e6fb84e308044fabd668cbd82":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0286b2875f7a4461851599cba6961bc7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0352a2da920a47b38208abbf227a38e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"058e301b87dd4177b6b0c24b93884c90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1936a1bd1369453b83ad8d582ae01619","placeholder":"â€‹","style":"IPY_MODEL_6c3cdbc7354b47dea11f85a6ad34b02e","value":"Generatingâ€‡validationâ€‡split:â€‡"}},"068296ebafd647fd962b7c5c0ccc890e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09715f8262ec4125b7a7280253e595dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c6d271ffebe4c8abc0ebf3b3aa1b843":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e0c243d319e41868d2bf432324b93e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10644c83b86d4188af054097e677eee8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a46d6bd329748048b08cffec15386e8","placeholder":"â€‹","style":"IPY_MODEL_ba355c4ef362474fb97aa0163a322921","value":"â€‡500k/500kâ€‡[00:01&lt;00:00,â€‡386kB/s]"}},"15fd060eb21e43d7b27b757dc09f51b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f396680277314b0c975fea03ae2e9c91","placeholder":"â€‹","style":"IPY_MODEL_0e0c243d319e41868d2bf432324b93e8","value":"tokenizer_config.json:â€‡100%"}},"17b4f0a795a148c88ec72f316956d7ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1936a1bd1369453b83ad8d582ae01619":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c261dc893894eab9f7fe791f68022dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dd29a12f91644dfbe6326ba6f1a30d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e8b9c13ccba4bd198124df85d2d93b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e741203ce874a8d942ce883a12081bf","max":9877979288,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec7c0ffc757643f3bceeff247e313659","value":67785307}},"1f513381788b46f18c5833d5f2d9ec25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ff58958a21f4ea39ce9ee1384689417":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20d50db6a28f4864a742bcf858f2ec14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22bdcac3acf842518978ed21da264c34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24ca02abf79e4104ba25f3e5bb156c40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ad974a24dbb4ee494d757f024843b71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57e1b5b822a24bd59ba65315a8ca565c","IPY_MODEL_365aa4ec1564439aad5905f5b0b4bb61","IPY_MODEL_b8916dae11054127b727dee91ba276f1"],"layout":"IPY_MODEL_ef34db0be4404c4aae5af7e413884e1e"}},"2c100069c794484fa312c438dac3c6a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c4af94ea4eb4306a5b36eaf287f6cd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cc305f5bd88457ea8a020b38ebcd037":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d23fbfaeae004b6383a79f64d171403f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5874890f49b84594a94fe34c5f2afe98","value":1}},"2e19a37424af4b5c92eb81e74e3ef54e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f1bc70f71cd462e807f669d8eef1231","placeholder":"â€‹","style":"IPY_MODEL_db41eaa736a843918aafb1146c8db992","value":"config.json:â€‡100%"}},"2e742995e5254542b77c7008db585c4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c0b8842934c64ab08b4934ed49dfa9b2","IPY_MODEL_8d90135affa94524897b8a79961e40d0","IPY_MODEL_d63e5d8295ac44ff97cbaeb20a4f72fe"],"layout":"IPY_MODEL_aac2d5ddb28042458d0aaabd436cd380"}},"2f1bc70f71cd462e807f669d8eef1231":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fb053ee95454ee59c0f443cea47954f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c6d271ffebe4c8abc0ebf3b3aa1b843","max":21,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45801b226a2442648bd75dd1bad6ba24","value":21}},"362ea8fa35d841c48e9597b5a33dfd56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c33246c98f84d6a9e2dce1cdb068d72","placeholder":"â€‹","style":"IPY_MODEL_8a4bc6ad4dc54202a714d9683c41dca3","value":"special_tokens_map.json:â€‡100%"}},"3646cc18ce4b4fe58c191f63f7b92fcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe709d095cf4400a9b6a987f32731888","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0352a2da920a47b38208abbf227a38e1","value":499723}},"365aa4ec1564439aad5905f5b0b4bb61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0286b2875f7a4461851599cba6961bc7","max":9894773440,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7594d9377d634f2fa0561a25f27032a6","value":627082}},"3a8217b1afbe4bae9e4aa0d06656dae2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c279af50bea4ff6b276cafaff6c4ad4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2d71b8af20b4b3e926966ccecc8e437","placeholder":"â€‹","style":"IPY_MODEL_96b2c05ac8b24107ba66cb9adcf4e32d","value":"model.safetensors.index.json:â€‡"}},"3d93b8ca94b74a10afe25e16b4976156":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fc9b0e2c1b34b259ffdd4c5f1dc5282":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"401c4e817e114920a70a6d82ca19b935":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45801b226a2442648bd75dd1bad6ba24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"486d1eec91014e6e9c70bada113f5000":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3c279af50bea4ff6b276cafaff6c4ad4","IPY_MODEL_6174496dbff247a79d8f0051e14d7fe4","IPY_MODEL_d1fe9762ed9246b3a17aae5c8e4f6ee3"],"layout":"IPY_MODEL_8ca11a7e1f0b4f73bfcc7af47dae9fdc"}},"4a46d6bd329748048b08cffec15386e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b45e931031e46f98ba1a8f84ffef97b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f973ae5462e44bfa14500918fd0e488","max":96,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd3c5a45df164571b19f9591af8bb841","value":96}},"514c9073a0924d1688941e6fc45d7919":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57e1b5b822a24bd59ba65315a8ca565c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dd7d60afc5545f29350ca66a0fe0ea1","placeholder":"â€‹","style":"IPY_MODEL_22bdcac3acf842518978ed21da264c34","value":"model-00002-of-00003.safetensors:â€‡â€‡â€‡0%"}},"5874890f49b84594a94fe34c5f2afe98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"59352ca976c146128d1c81d59470b1dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c9e7941b1a14233918ba3d6235c517d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e15424cec4e4f7ea2a81445520963df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f8c41d11abf4a169acd7936a21f2021":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f973ae5462e44bfa14500918fd0e488":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61399a20b820409491e41d6112c7a469":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8396384996a9429584d1a770bbd04ebe","placeholder":"â€‹","style":"IPY_MODEL_59352ca976c146128d1c81d59470b1dd","value":"Generatingâ€‡trainâ€‡split:â€‡"}},"6174496dbff247a79d8f0051e14d7fe4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bd79c878db743f5bf13c26524339115","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f8c41d11abf4a169acd7936a21f2021","value":1}},"6184e29664cd473b94f38fe38d97f470":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6204dffe6e9642448a05d767794495de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62b5b4e5e5bf448685b507f8bdd4b38a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"642a1075ae2b488d97748eaa27d97ae3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65539231f64d461bae768c8f051c0d5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83264cc56e2642be84fea1bad362f334","placeholder":"â€‹","style":"IPY_MODEL_068296ebafd647fd962b7c5c0ccc890e","value":"â€‡96.0/96.0â€‡[00:00&lt;00:00,â€‡10.5kB/s]"}},"6aeb49e27b014c26b9f2a8c062904f08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be8eb938d9f34eb7b9b8875274d6a49f","IPY_MODEL_dad80ce2460c4021914104976f7e572c","IPY_MODEL_a9f90d048e744421a42e436bfc70e5e6"],"layout":"IPY_MODEL_cf287b73a2374305acc7550a87bf330c"}},"6c3cdbc7354b47dea11f85a6ad34b02e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"724ed8ce60124943ab0f55363390f681":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"752ab4def4cb49dd8f484eeedd72c461":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7594d9377d634f2fa0561a25f27032a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7e741203ce874a8d942ce883a12081bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"816fa6e9e41b469ebfdf4b86d2670a4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bfd39638019645df9852446420eedb12","IPY_MODEL_2fb053ee95454ee59c0f443cea47954f","IPY_MODEL_d263477398fa43eea722a6cd05af442f"],"layout":"IPY_MODEL_1dd29a12f91644dfbe6326ba6f1a30d3"}},"82751a0bdf534629a63f20cc60b6c4c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9afd6d0156549c789406d449c16325e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ecfab6c9fab345f78225f6721ec68888","value":1}},"83264cc56e2642be84fea1bad362f334":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8332280cc26d4671a711005353b05216":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8396384996a9429584d1a770bbd04ebe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84c00a8e95d04437a97ec0669d4aad0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d93b8ca94b74a10afe25e16b4976156","max":542,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8adff43f4a854025b77b63ad15ae6913","value":542}},"84ee44d25b2348fe84f84cff5f71ba8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"858dd835c2b94b64afbb7a989a91eb70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87a5f2c3506645558d6372420dbb0156":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e19a37424af4b5c92eb81e74e3ef54e","IPY_MODEL_84c00a8e95d04437a97ec0669d4aad0e","IPY_MODEL_bdeba484286445ce8182f7f37c210d8e"],"layout":"IPY_MODEL_24ca02abf79e4104ba25f3e5bb156c40"}},"8a4bc6ad4dc54202a714d9683c41dca3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8adff43f4a854025b77b63ad15ae6913":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ca11a7e1f0b4f73bfcc7af47dae9fdc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d8471641f4543b09a2d0eaa61b95066":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d90135affa94524897b8a79961e40d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb0131ef72d8472a9f0e59e42f82df7e","max":7180987992,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84ee44d25b2348fe84f84cff5f71ba8a","value":633885}},"8dd7d60afc5545f29350ca66a0fe0ea1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e325292c0544621b215ba471ea76c86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c261dc893894eab9f7fe791f68022dc","placeholder":"â€‹","style":"IPY_MODEL_642a1075ae2b488d97748eaa27d97ae3","value":"â€‡89530/0â€‡[00:01&lt;00:00,â€‡52778.48â€‡examples/s]"}},"8fd8bcdc8de443e1b4f4df811cc437ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96b2c05ac8b24107ba66cb9adcf4e32d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98cc623bb4614e83a6dbe045934ad5b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bd79c878db743f5bf13c26524339115":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9c33246c98f84d6a9e2dce1cdb068d72":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9de34c43970147f08d2f4be1bc0a7043":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a15ae7aae4ba4806b296e15f4559091c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9de34c43970147f08d2f4be1bc0a7043","placeholder":"â€‹","style":"IPY_MODEL_a3e40221fb5c49b5801f47ba2cd668fe","value":"tokenizer.model:â€‡100%"}},"a2bbe3de651a4d8289e89d13ec241965":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3e40221fb5c49b5801f47ba2cd668fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9f90d048e744421a42e436bfc70e5e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c100069c794484fa312c438dac3c6a7","placeholder":"â€‹","style":"IPY_MODEL_1ff58958a21f4ea39ce9ee1384689417","value":"â€‡0/3â€‡[00:00&lt;?,â€‡?it/s]"}},"aac2d5ddb28042458d0aaabd436cd380":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad16e5682c9948bd933c373be9706f27":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad4b2837f101433c8b1eb9e6689f9e69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a8217b1afbe4bae9e4aa0d06656dae2","placeholder":"â€‹","style":"IPY_MODEL_8fd8bcdc8de443e1b4f4df811cc437ab","value":"â€‡22383/0â€‡[00:00&lt;00:00,â€‡44462.65â€‡examples/s]"}},"b2e2b96ec57b467c9823fb216424bcd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61399a20b820409491e41d6112c7a469","IPY_MODEL_2cc305f5bd88457ea8a020b38ebcd037","IPY_MODEL_8e325292c0544621b215ba471ea76c86"],"layout":"IPY_MODEL_fe1754166d234430afd2fad70cbb943d"}},"b2fc86f28d4542069c7513526721dfbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b35af9be1d36423b9831635c584392ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6204dffe6e9642448a05d767794495de","placeholder":"â€‹","style":"IPY_MODEL_3fc9b0e2c1b34b259ffdd4c5f1dc5282","value":"â€‡260/260â€‡[00:00&lt;00:00,â€‡28.2kB/s]"}},"b8916dae11054127b727dee91ba276f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfb83bbe6f104654a3c1ae9167376466","placeholder":"â€‹","style":"IPY_MODEL_1f513381788b46f18c5833d5f2d9ec25","value":"â€‡627k/9.89Gâ€‡[00:02&lt;9:14:09,â€‡298kB/s]"}},"ba355c4ef362474fb97aa0163a322921":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba659b545eb343a1a117eb6dd0dbadaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc9a2a496ef741309780f986b092cf74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_362ea8fa35d841c48e9597b5a33dfd56","IPY_MODEL_4b45e931031e46f98ba1a8f84ffef97b","IPY_MODEL_65539231f64d461bae768c8f051c0d5f"],"layout":"IPY_MODEL_858dd835c2b94b64afbb7a989a91eb70"}},"bdeba484286445ce8182f7f37c210d8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_514c9073a0924d1688941e6fc45d7919","placeholder":"â€‹","style":"IPY_MODEL_20d50db6a28f4864a742bcf858f2ec14","value":"â€‡542/542â€‡[00:00&lt;00:00,â€‡54.4kB/s]"}},"be8eb938d9f34eb7b9b8875274d6a49f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c4af94ea4eb4306a5b36eaf287f6cd6","placeholder":"â€‹","style":"IPY_MODEL_62b5b4e5e5bf448685b507f8bdd4b38a","value":"Fetchingâ€‡3â€‡files:â€‡â€‡â€‡0%"}},"beba5d5115064a37b7acd4a380477d4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0086927e6fb84e308044fabd668cbd82","placeholder":"â€‹","style":"IPY_MODEL_724ed8ce60124943ab0f55363390f681","value":"â€‡67.8M/9.88Gâ€‡[00:12&lt;28:55,â€‡5.65MB/s]"}},"bfd39638019645df9852446420eedb12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad16e5682c9948bd933c373be9706f27","placeholder":"â€‹","style":"IPY_MODEL_401c4e817e114920a70a6d82ca19b935","value":"added_tokens.json:â€‡100%"}},"c0b8842934c64ab08b4934ed49dfa9b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2bbe3de651a4d8289e89d13ec241965","placeholder":"â€‹","style":"IPY_MODEL_b2fc86f28d4542069c7513526721dfbd","value":"model-00003-of-00003.safetensors:â€‡â€‡â€‡0%"}},"c21bc9d9a6e34ea7b762f519ae5db8d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3e327b5f82341e8a95eda48212e02f3","IPY_MODEL_1e8b9c13ccba4bd198124df85d2d93b2","IPY_MODEL_beba5d5115064a37b7acd4a380477d4a"],"layout":"IPY_MODEL_ebe10c4d3ab249d08682bceeb122d8ab"}},"c2d71b8af20b4b3e926966ccecc8e437":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c340f53d926c46b9aa07efb8420a7076":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_15fd060eb21e43d7b27b757dc09f51b4","IPY_MODEL_cae8934db0e34374bd98e33d910971f4","IPY_MODEL_b35af9be1d36423b9831635c584392ff"],"layout":"IPY_MODEL_d8254b8011f64977b328d3d498cb5b40"}},"c3e327b5f82341e8a95eda48212e02f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17b4f0a795a148c88ec72f316956d7ef","placeholder":"â€‹","style":"IPY_MODEL_98cc623bb4614e83a6dbe045934ad5b6","value":"model-00001-of-00003.safetensors:â€‡â€‡â€‡1%"}},"c8c601c647524c7daeaf0330771dbcd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cae4909e0c754d1ea576ec0ac3f9f5ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a15ae7aae4ba4806b296e15f4559091c","IPY_MODEL_3646cc18ce4b4fe58c191f63f7b92fcb","IPY_MODEL_10644c83b86d4188af054097e677eee8"],"layout":"IPY_MODEL_e8530c7689df4f968d475a1533b57f6a"}},"cae8934db0e34374bd98e33d910971f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8332280cc26d4671a711005353b05216","max":260,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf19364c08d94571a7fea9a4d018cc01","value":260}},"cf19364c08d94571a7fea9a4d018cc01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf287b73a2374305acc7550a87bf330c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfb83bbe6f104654a3c1ae9167376466":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1fe9762ed9246b3a17aae5c8e4f6ee3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e15424cec4e4f7ea2a81445520963df","placeholder":"â€‹","style":"IPY_MODEL_5c9e7941b1a14233918ba3d6235c517d","value":"â€‡28.1k/?â€‡[00:00&lt;00:00,â€‡1.17MB/s]"}},"d23fbfaeae004b6383a79f64d171403f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d263477398fa43eea722a6cd05af442f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6184e29664cd473b94f38fe38d97f470","placeholder":"â€‹","style":"IPY_MODEL_d8f6cfd471e545a3bd5058ff31f7680d","value":"â€‡21.0/21.0â€‡[00:00&lt;00:00,â€‡2.19kB/s]"}},"d63e5d8295ac44ff97cbaeb20a4f72fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_752ab4def4cb49dd8f484eeedd72c461","placeholder":"â€‹","style":"IPY_MODEL_ba659b545eb343a1a117eb6dd0dbadaf","value":"â€‡634k/7.18Gâ€‡[00:01&lt;5:25:45,â€‡367kB/s]"}},"d8254b8011f64977b328d3d498cb5b40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8f6cfd471e545a3bd5058ff31f7680d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9afd6d0156549c789406d449c16325e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"dad80ce2460c4021914104976f7e572c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8c601c647524c7daeaf0330771dbcd6","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_09715f8262ec4125b7a7280253e595dd","value":0}},"db41eaa736a843918aafb1146c8db992":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd3c5a45df164571b19f9591af8bb841":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8530c7689df4f968d475a1533b57f6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb0131ef72d8472a9f0e59e42f82df7e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebe10c4d3ab249d08682bceeb122d8ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec7c0ffc757643f3bceeff247e313659":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ecfab6c9fab345f78225f6721ec68888":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef34db0be4404c4aae5af7e413884e1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f396680277314b0c975fea03ae2e9c91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe1754166d234430afd2fad70cbb943d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe709d095cf4400a9b6a987f32731888":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffb68d6bdbba4db19831d1d6183fdc3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_058e301b87dd4177b6b0c24b93884c90","IPY_MODEL_82751a0bdf534629a63f20cc60b6c4c5","IPY_MODEL_ad4b2837f101433c8b1eb9e6689f9e69"],"layout":"IPY_MODEL_8d8471641f4543b09a2d0eaa61b95066"}}}}},"nbformat":4,"nbformat_minor":5}
