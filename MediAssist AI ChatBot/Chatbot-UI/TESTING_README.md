# System Testing Documentation - Quick Overview

## ğŸ“ Files Created for Your Testing Documentation

### 1. **TEST_CASES_DOCUMENTATION.md**
   - **What it is:** Complete test case definitions with expected results
   - **Contains:**
     - 6 detailed use cases with step-by-step GUI sequences
     - QoS testing methodology
     - Performance, consistency, accuracy, and loss metrics
     - Expected results and pass/fail criteria
   - **How to use:** This is your reference guide showing what to test and document

### 2. **test_performance_metrics.py**
   - **What it is:** Automated testing script
   - **What it does:**
     - Measures response times for different query types
     - Tests consistency across multiple trials
     - Tests all 9 medical departments
     - Generates JSON files with all metrics
   - **How to run:**
     ```bash
     python test_performance_metrics.py
     ```
   - **Output:** 3 JSON files with performance data

### 3. **TESTING_QUICK_START_GUIDE.md**
   - **What it is:** Step-by-step instructions
   - **Contains:**
     - How to run automated tests
     - Screenshot collection checklist
     - How to create documentation
     - Data visualization tips
     - Grading rubric alignment
   - **How to use:** Follow this guide to complete your documentation

---

## ğŸ¯ Your Task

You need to create a document (Google Docs, Word, or PowerPoint) that includes:

### Part 1: Use Case Testing (60% of grade)
- **6 use cases** each with multiple GUI screenshots showing the sequence
- Screenshots should show:
  - Before state
  - Action being performed
  - After state/result
- Each screenshot should have a caption explaining what's happening

### Part 2: QoS Testing Results (40% of grade)
Four main categories:

1. **Performance** (25%)
   - Response times
   - Token generation speed
   - Loading times
   - Emergency detection time

2. **Consistency** (25%)
   - Same query tested 5 times
   - Measure response length variance
   - Structure adherence
   - Consistency score

3. **Accuracy** (25%)
   - Verify responses against Mayo Clinic, CDC, etc.
   - Fact-check medical information
   - Calculate accuracy percentage

4. **Loss** (25%)
   - Training loss values
   - Validation loss values
   - Model improvement metrics
   - Loss convergence chart

---

## ğŸ“‹ Quick Start (3 Steps)

### Step 1: Run Automated Tests (30-45 minutes)
```bash
cd C:\SJSU\Sem-4\298B\Chatbot
python test_performance_metrics.py
```

This generates 3 JSON files with your metrics:
- `performance_results_[timestamp].json`
- `consistency_results_[timestamp].json`
- `department_results_[timestamp].json`

### Step 2: Collect Screenshots (1-2 hours)
```bash
streamlit run app.py
```

Follow the checklist in `TESTING_QUICK_START_GUIDE.md` to collect ~20 screenshots for all 6 use cases.

### Step 3: Create Documentation (2-3 hours)
1. Open Google Docs or Word
2. Create sections for each use case
3. Insert screenshots with captions
4. Copy metrics from JSON files into tables
5. Create charts from the data
6. Add your analysis and conclusions

---

## ğŸ“Š Example Structure for Your Document

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    MEDIASSIST AI - SYSTEM TESTING DOCUMENTATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TABLE OF CONTENTS
1. Introduction
2. Use Case Testing
   2.1 Use Case 1: General Medical Query
   2.2 Use Case 2: Emergency Detection
   2.3 Use Case 3: Department Quick Prompts
   2.4 Use Case 4: Multi-Turn Conversation
   2.5 Use Case 5: Export Chat
   2.6 Use Case 6: Temperature Control
3. System QoS Testing
   3.1 Performance Testing
   3.2 Consistency Testing
   3.3 Accuracy Testing
   3.4 Model Loss Metrics
4. Test Results Summary
5. Conclusions

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SECTION 1: INTRODUCTION
- Brief project overview
- Testing objectives
- Testing environment setup

SECTION 2: USE CASE TESTING

2.1 USE CASE 1: GENERAL MEDICAL QUERY - HEADACHE
Objective: Test comprehensive medical information delivery

Step 1: Application Launch
[Screenshot UC1_Step1_AppLaunch.png]
Caption: "Application loads with medical header, privacy 
consent, and HIPAA compliance notice visible."

Expected Result: âœ…
- Main interface loads
- Privacy consent displayed
- Medical disclaimer visible

Actual Result: âœ… PASS
- All elements rendered correctly
- Load time: 1.8 seconds

Step 2: Privacy Consent
[Screenshot UC1_Step2_Consent.png]
...

[Continue for all 7 steps]

Test Summary for UC1:
Overall Result: âœ… PASS
Response Time: 20.5 seconds
Response Length: 342 words
All 6 sections present: âœ…

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SECTION 3: SYSTEM QOS TESTING

3.1 PERFORMANCE TESTING

Test Configuration:
- Hardware: [Your specs]
- Model: MedLlama-3b GGUF Q4_K_M
- Date: [Test date]

Performance Results:

| Test ID | Query Type | Response Time | Tokens/sec | Pass/Fail |
|---------|-----------|---------------|------------|-----------|
| TC-P01  | Short     | 12.5s        | 8.5        | âœ… Pass   |
| TC-P02  | Medium    | 18.3s        | 9.2        | âœ… Pass   |
| TC-P03  | Long      | 25.7s        | 8.8        | âœ… Pass   |

[Chart: Response Time by Query Length]
[Bar chart visualization here]

Performance Summary:
âœ… Average Response Time: 19.1s (Target: <30s)
âœ… Average Token Speed: 9.0 tok/s (Target: >5 tok/s)
âœ… Emergency Detection: 0.8s (Target: <2s)

Overall Performance Score: 92.5% - EXCELLENT âœ…

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

3.2 CONSISTENCY TESTING

Method: Same query tested 5 times at temperature 0.2

Results:
| Trial | Word Count | Sections | Score |
|-------|-----------|----------|-------|
| 1     | 287       | 6/6      | 95%   |
| 2     | 294       | 6/6      | 97%   |
| 3     | 281       | 6/6      | 93%   |
| 4     | 292       | 6/6      | 96%   |
| 5     | 289       | 6/6      | 95%   |

[Chart: Response Length Consistency]
[Line chart with variance bands]

Consistency Summary:
âœ… Average Consistency: 95.2%
âœ… Length Variance: Â±5%
âœ… Structure Match: 100%

Overall Consistency Score: 95.2% - EXCELLENT âœ…

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

3.3 ACCURACY TESTING

Validation Sources: Mayo Clinic, CDC, NIH

| Query | Facts Checked | Correct | Accuracy | Source |
|-------|--------------|---------|----------|---------|
| COVID symptoms | 8 | 8 | 100% | CDC |
| Diabetes info | 10 | 9 | 90% | Mayo Clinic |
| Hypertension | 7 | 7 | 100% | NIH |

Overall Accuracy: 95.8% - EXCELLENT âœ…

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

3.4 MODEL LOSS METRICS

Fine-tuning Results:
- Base Model Loss: 2.45
- Fine-tuned Training Loss: 0.87
- Fine-tuned Validation Loss: 0.93
- Improvement: 64.5% reduction

[Chart: Training Loss Curve]
[Line chart showing loss over epochs]

Model Quality: EXCELLENT âœ…

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SECTION 4: TEST RESULTS SUMMARY

Overall System Quality Scores:

| QoS Parameter | Score  | Target | Result |
|--------------|--------|--------|---------|
| Performance  | 92.5%  | â‰¥85%   | âœ… EXCELLENT |
| Consistency  | 95.2%  | â‰¥90%   | âœ… EXCELLENT |
| Accuracy     | 95.8%  | â‰¥90%   | âœ… EXCELLENT |
| Model Loss   | 0.87   | <1.5   | âœ… EXCELLENT |

Test Summary:
- Total Tests: 47
- Passed: 46
- Failed: 1 (minor)
- Pass Rate: 97.9%

OVERALL SYSTEM STATUS: âœ… EXCELLENT

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SECTION 5: CONCLUSIONS

Key Achievements:
1. Emergency detection achieves 100% accuracy in <1 second
2. Medical information accuracy validated at 95.8%
3. Response consistency demonstrates reliable performance
4. Model fine-tuning achieved 64.5% loss reduction
5. All 9 medical departments tested and validated

Areas of Excellence:
- Comprehensive response structure (6 sections)
- Fast emergency response protocol
- Consistent multi-turn conversation handling
- Professional medical disclaimer compliance

Recommendations:
[Your analysis and future improvements]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ“ˆ Charts You Should Create

1. **Response Time Bar Chart**
   - X: Query types (Short, Medium, Long)
   - Y: Response time in seconds

2. **Consistency Line Chart**
   - X: Trial number (1-5)
   - Y: Word count
   - Show variance bands

3. **Department Performance Chart**
   - X: All 9 departments
   - Y: Response time

4. **Training Loss Curve**
   - X: Epochs or steps
   - Y: Loss value
   - Two lines: training & validation

5. **Accuracy Comparison**
   - Pie chart or bar chart
   - Facts correct vs incorrect

6. **Overall QoS Dashboard**
   - 4 gauges showing Performance, Consistency, Accuracy, Loss

---

## âœ… Quality Checklist for Excellent Grade

### Content (50%):
- [ ] All 6 use cases documented
- [ ] 20+ high-quality screenshots
- [ ] Complete GUI sequences shown
- [ ] All 4 QoS parameters tested
- [ ] Actual test data (not just templates)

### Presentation (30%):
- [ ] Professional formatting
- [ ] Clear headings and structure
- [ ] All screenshots have captions
- [ ] Tables are well-formatted
- [ ] Charts/graphs included
- [ ] Color-coded pass/fail

### Analysis (20%):
- [ ] Not just data, but interpretation
- [ ] Conclusions for each section
- [ ] Overall assessment
- [ ] Recommendations
- [ ] Comparison with targets/thresholds

---

## ğŸ“ Need Help?

### If automated tests fail:
1. Check that model file exists: `models/medllama-3b-gguf/medllama-3b-q4_k_m.gguf`
2. Ensure all dependencies installed: `pip install -r requirements.txt`
3. Check Python version: `python --version` (should be 3.8+)

### If screenshots are unclear:
1. Use full screen mode (F11 in browser)
2. Use Windows Snipping Tool (Win + Shift + S)
3. Don't resize - keep original resolution

### If chatbot responses are too short:
1. Verify `constants.py` has updated system prompt
2. Check `max_new_tokens=1024` in `components.py`
3. Restart Streamlit app

---

## ğŸ¯ Time Estimate

| Task | Time |
|------|------|
| Run automated tests | 30-45 min |
| Collect screenshots | 1-2 hours |
| Create documentation | 2-3 hours |
| Create charts | 30-60 min |
| Write analysis | 1 hour |
| **Total** | **5-8 hours** |

---

## ğŸŒŸ Pro Tips

1. **Do screenshots first** - If app crashes, you have visuals
2. **Run tests overnight** - Let script run while you sleep
3. **Use templates** - Start with Google Docs template
4. **Annotate screenshots** - Use drawing tools to highlight features
5. **Show comparisons** - Before/after, expected vs actual
6. **Be thorough** - More is better than less
7. **Professional tone** - Write as if for a client/stakeholder

---

## ğŸ“š Files Reference

```
Chatbot/
â”œâ”€â”€ TEST_CASES_DOCUMENTATION.md      â† Detailed test cases
â”œâ”€â”€ test_performance_metrics.py      â† Automated testing script
â”œâ”€â”€ TESTING_QUICK_START_GUIDE.md     â† Step-by-step guide
â”œâ”€â”€ TESTING_README.md                â† This file
â”‚
â””â”€â”€ Generated by tests:
    â”œâ”€â”€ performance_results_[time].json
    â”œâ”€â”€ consistency_results_[time].json
    â””â”€â”€ department_results_[time].json
```

---

## ğŸš€ Getting Started Now

1. **Read** `TESTING_QUICK_START_GUIDE.md` (10 min)
2. **Run** `python test_performance_metrics.py` (45 min)
3. **Collect** screenshots following the guide (2 hours)
4. **Create** your document with all the data (3 hours)
5. **Submit** and get that excellent grade! ğŸ“

**Good luck! You've got this! ğŸ‰**

